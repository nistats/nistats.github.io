{
  "nbformat_minor": 0, 
  "nbformat": 4, 
  "cells": [
    {
      "execution_count": null, 
      "cell_type": "code", 
      "source": [
        "%matplotlib inline"
      ], 
      "outputs": [], 
      "metadata": {
        "collapsed": false
      }
    }, 
    {
      "source": [
        "\nMinimal script for preprocessing single-subject data (two session)\n==================================================================\nAuthor: DOHMATOB Elvis, Bertrand Thirion, 2015\n\nFor details on the data, please see:\nHenson, R.N., Goshen-Gottstein, Y., Ganel, T., Otten, L.J., Quayle, A.,\nRugg, M.D. Electrophysiological and haemodynamic correlates of face\nperception, recognition and priming. Cereb Cortex. 2003 Jul;13(7):793-805.\nhttp://www.dx.doi.org/10.1093/cercor/13.7.793\n\nNote: this example takes a lot of time because the input are lists of 3D images\nsampled in different position (encoded by different) affine functions.\n\n"
      ], 
      "cell_type": "markdown", 
      "metadata": {}
    }, 
    {
      "execution_count": null, 
      "cell_type": "code", 
      "source": [
        "print(__doc__)\n\n# Standard imports\nimport numpy as np\nfrom scipy.io import loadmat\nimport pandas as pd\n\n# Imports for GLM\nfrom nilearn.image import concat_imgs, resample_img, mean_img\nfrom nistats.design_matrix import make_design_matrix\nfrom nistats.first_level_model import FirstLevelModel\nfrom nistats.datasets import fetch_spm_multimodal_fmri"
      ], 
      "outputs": [], 
      "metadata": {
        "collapsed": false
      }
    }, 
    {
      "source": [
        "Fetch spm multimodal_faces data\n\n"
      ], 
      "cell_type": "markdown", 
      "metadata": {}
    }, 
    {
      "execution_count": null, 
      "cell_type": "code", 
      "source": [
        "subject_data = fetch_spm_multimodal_fmri()"
      ], 
      "outputs": [], 
      "metadata": {
        "collapsed": false
      }
    }, 
    {
      "source": [
        "Experimental paradigm specification\n\n"
      ], 
      "cell_type": "markdown", 
      "metadata": {}
    }, 
    {
      "execution_count": null, 
      "cell_type": "code", 
      "source": [
        "tr = 2.\nslice_time_ref = 0.\ndrift_model = 'Cosine'\nhrf_model = 'spm + derivative'\nperiod_cut = 128."
      ], 
      "outputs": [], 
      "metadata": {
        "collapsed": false
      }
    }, 
    {
      "source": [
        "Resample the images\n\n"
      ], 
      "cell_type": "markdown", 
      "metadata": {}
    }, 
    {
      "execution_count": null, 
      "cell_type": "code", 
      "source": [
        "fmri_img = [concat_imgs(subject_data.func1, auto_resample=True),\n            concat_imgs(subject_data.func2, auto_resample=True)]\naffine, shape = fmri_img[0].affine, fmri_img[0].shape\nprint('Resampling the second image (this takes time)...')\nfmri_img[1] = resample_img(fmri_img[1], affine, shape[:3])"
      ], 
      "outputs": [], 
      "metadata": {
        "collapsed": false
      }
    }, 
    {
      "source": [
        "Create mean image for display\n\n"
      ], 
      "cell_type": "markdown", 
      "metadata": {}
    }, 
    {
      "execution_count": null, 
      "cell_type": "code", 
      "source": [
        "mean_image = mean_img(fmri_img)"
      ], 
      "outputs": [], 
      "metadata": {
        "collapsed": false
      }
    }, 
    {
      "source": [
        "Make design matrices\n\n"
      ], 
      "cell_type": "markdown", 
      "metadata": {}
    }, 
    {
      "execution_count": null, 
      "cell_type": "code", 
      "source": [
        "design_matrices = []\nfor idx in range(len(fmri_img)):\n    # Build paradigm\n    n_scans = fmri_img[idx].shape[-1]\n    timing = loadmat(getattr(subject_data, \"trials_ses%i\" % (idx + 1)),\n                     squeeze_me=True, struct_as_record=False)\n\n    faces_onsets = timing['onsets'][0].ravel()\n    scrambled_onsets = timing['onsets'][1].ravel()\n    onsets = np.hstack((faces_onsets, scrambled_onsets))\n    onsets *= tr  # because onsets were reporting in 'scans' units\n    conditions = (['faces'] * len(faces_onsets) +\n                  ['scrambled'] * len(scrambled_onsets))\n    paradigm = pd.DataFrame({'trial_type': conditions, 'onset': onsets})\n\n    # Build design matrix\n    frame_times = np.arange(n_scans) * tr\n    design_matrix = make_design_matrix(\n        frame_times, paradigm, hrf_model=hrf_model, drift_model=drift_model,\n        period_cut=period_cut)\n    design_matrices.append(design_matrix)"
      ], 
      "outputs": [], 
      "metadata": {
        "collapsed": false
      }
    }, 
    {
      "source": [
        "We can specify basic contrasts (To get beta maps)\n\n"
      ], 
      "cell_type": "markdown", 
      "metadata": {}
    }, 
    {
      "execution_count": null, 
      "cell_type": "code", 
      "source": [
        "contrast_matrix = np.eye(design_matrix.shape[1])\ncontrasts = dict([(column, contrast_matrix[i])\n                  for i, column in enumerate(design_matrix.columns)])"
      ], 
      "outputs": [], 
      "metadata": {
        "collapsed": false
      }
    }, 
    {
      "source": [
        "Instead in this example we define more interesting contrasts\n\n"
      ], 
      "cell_type": "markdown", 
      "metadata": {}
    }, 
    {
      "execution_count": null, 
      "cell_type": "code", 
      "source": [
        "contrasts = {\n    'faces-scrambled': contrasts['faces'] - contrasts['scrambled'],\n    'scrambled-faces': -contrasts['faces'] + contrasts['scrambled'],\n    'effects_of_interest': np.vstack((contrasts['faces'],\n                                      contrasts['scrambled']))\n    }"
      ], 
      "outputs": [], 
      "metadata": {
        "collapsed": false
      }
    }, 
    {
      "source": [
        "Fit GLM\n\n"
      ], 
      "cell_type": "markdown", 
      "metadata": {}
    }, 
    {
      "execution_count": null, 
      "cell_type": "code", 
      "source": [
        "print('Fitting a GLM')\nfmri_glm = FirstLevelModel(tr, slice_time_ref)\nfmri_glm = fmri_glm.fit(fmri_img, design_matrices=design_matrices)"
      ], 
      "outputs": [], 
      "metadata": {
        "collapsed": false
      }
    }, 
    {
      "source": [
        "Compute contrast maps\n\n"
      ], 
      "cell_type": "markdown", 
      "metadata": {}
    }, 
    {
      "execution_count": null, 
      "cell_type": "code", 
      "source": [
        "print('Computing contrasts')\nfrom nilearn import plotting\n\nfor contrast_id, contrast_val in contrasts.items():\n    print(\"\\tcontrast id: %s\" % contrast_id)\n    z_map = fmri_glm.compute_contrast(\n        contrast_val, output_type='z_score')\n    plotting.plot_stat_map(\n        z_map, bg_img=mean_image, threshold=3.0, display_mode='z',\n        cut_coords=3, black_bg=True, title=contrast_id)\n\nplotting.show()"
      ], 
      "outputs": [], 
      "metadata": {
        "collapsed": false
      }
    }
  ], 
  "metadata": {
    "kernelspec": {
      "display_name": "Python 2", 
      "name": "python2", 
      "language": "python"
    }, 
    "language_info": {
      "mimetype": "text/x-python", 
      "nbconvert_exporter": "python", 
      "name": "python", 
      "file_extension": ".py", 
      "version": "2.7.12", 
      "pygments_lexer": "ipython2", 
      "codemirror_mode": {
        "version": 2, 
        "name": "ipython"
      }
    }
  }
}