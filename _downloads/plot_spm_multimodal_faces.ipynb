{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "%matplotlib inline"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Single-subject data (two sessions) in native space\n==================================================\n\nThe example shows the analysis of an SPM dataset studying face perception.\nThe anaylsis is performed in native spave. Realignment parameters are provided\nwith the input images, but those have not been resampled to a common space.\n\nThe experimental paradigm is simple, with two conditions; viewing a\nface image or a scrambled face image, supposedly with the same\nlow-level statistical properties, to find face-specific responses.\n\nFor details on the data, please see:\nHenson, R.N., Goshen-Gottstein, Y., Ganel, T., Otten, L.J., Quayle, A.,\nRugg, M.D. Electrophysiological and haemodynamic correlates of face\nperception, recognition and priming. Cereb Cortex. 2003 Jul;13(7):793-805.\nhttp://www.dx.doi.org/10.1093/cercor/13.7.793\n\nThis example takes a lot of time because the input are lists of 3D images\nsampled in different position (encoded by different) affine functions.\n\n\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "print(__doc__)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Fetch spm multimodal_faces data\n\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "from nistats.datasets import fetch_spm_multimodal_fmri\nsubject_data = fetch_spm_multimodal_fmri()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Timing and design matrix parameter specification\n\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "tr = 2.  # repetition time, in seconds\nslice_time_ref = 0.  # we will sample the design matrix at the beggining of each acquisition\ndrift_model = 'Cosine'  # We use a discrete cosin transform to model signal drifts.\nperiod_cut = 128.  # The cutoff for the drift model is 1/128 Hz.\nhrf_model = 'spm + derivative'  # The hemodunamic response finction is the SPM canonical one"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Resample the images.\n\nThis is achieved by the concat_imgs function of Nilearn.\n\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "from nilearn.image import concat_imgs, resample_img, mean_img\nfmri_img = [concat_imgs(subject_data.func1, auto_resample=True),\n            concat_imgs(subject_data.func2, auto_resample=True)]\naffine, shape = fmri_img[0].affine, fmri_img[0].shape\nprint('Resampling the second image (this takes time)...')\nfmri_img[1] = resample_img(fmri_img[1], affine, shape[:3])"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Create mean image for display\n\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "mean_image = mean_img(fmri_img)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Make design matrices\n\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "import numpy as np\nimport pandas as pd\nfrom nistats.design_matrix import make_first_level_design_matrix\ndesign_matrices = []"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "loop over the two sessions\n\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "for idx, img in enumerate(fmri_img, start=1):\n    # Build experimental paradigm\n    n_scans = img.shape[-1]\n    events = pd.read_table(subject_data['events{}'.format(idx)])\n    # Define the sampling times for the design matrix\n    frame_times = np.arange(n_scans) * tr\n    # Build design matrix with the reviously defined parameters\n    design_matrix = make_first_level_design_matrix(\n            frame_times,\n            events,\n            hrf_model=hrf_model,\n            drift_model=drift_model,\n            period_cut=period_cut,\n            )\n\n    # put the design matrices in a list\n    design_matrices.append(design_matrix)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "We can specify basic contrasts (to get beta maps).\nWe start by specifying canonical contrast that isolate design matrix columns\n\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "contrast_matrix = np.eye(design_matrix.shape[1])\nbasic_contrasts = dict([(column, contrast_matrix[i])\n                  for i, column in enumerate(design_matrix.columns)])"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "We actually want more interesting contrasts. The simplest contrast\njust makes the difference between the two main conditions.  We\ndefine the two opposite versions to run one-tail t-tests.  We also\ndefine the effects of interest contrast, a 2-dimensional contrasts\nspanning the two conditions.\n\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "contrasts = {\n    'faces-scrambled': basic_contrasts['faces'] - basic_contrasts['scrambled'],\n    'scrambled-faces': -basic_contrasts['faces'] + basic_contrasts['scrambled'],\n    'effects_of_interest': np.vstack((basic_contrasts['faces'],\n                                      basic_contrasts['scrambled']))\n    }"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Fit the GLM -- 2 sessions.\nImports for GLM, the sepcify, then fit.\n\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "from nistats.first_level_model import FirstLevelModel\nprint('Fitting a GLM')\nfmri_glm = FirstLevelModel()\nfmri_glm = fmri_glm.fit(fmri_img, design_matrices=design_matrices)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Compute contrast-related statistical maps (in z-scale), and plot them\n\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "print('Computing contrasts')\nfrom nilearn import plotting\n\n# Iterate on contrasts\nfor contrast_id, contrast_val in contrasts.items():\n    print(\"\\tcontrast id: %s\" % contrast_id)\n    # compute the contrasts\n    z_map = fmri_glm.compute_contrast(\n        contrast_val, output_type='z_score')\n    # plot the contrasts as soon as they're generated\n    # the display is overlayed on the mean fMRI image\n    # a threshold of 3.0 is used. More sophisticated choices are possible.\n    plotting.plot_stat_map(\n        z_map, bg_img=mean_image, threshold=3.0, display_mode='z',\n        cut_coords=3, black_bg=True, title=contrast_id)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Show the resulting maps: We observe that the analysis results in\nwide activity for the 'effects of interest' contrast, showing the\nimplications of large portions of the visual cortex in the\nconditions. By contrast, the differential effect between \"faces\" and\n\"scambled\" involves sparser, more anterior and lateral regions. It\ndisplays also some responses in the frontal lobe.\n\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "plotting.show()"
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.6.6"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}