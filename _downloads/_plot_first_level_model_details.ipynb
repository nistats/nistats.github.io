{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "%matplotlib inline"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "\nSyntaxError\n===========\n\nExample script with invalid Python syntax\n\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "\"\"\"Studying firts-level-model details in a trials-and-error fashion\n================================================================\n\nIn this tutorial, we study the parametrization of the first-level\nmodel used for fMRI data analysis and clarify their impact on the\nresults of the analysis.\n\nWe use an exploratory approach, in which we incrementally include some\nnew features in the analysis and look at the outcome, i.e. the\nresulting brain maps.\n\nReaders without prior experience in fMRI data analysis should first\nrun the plot_sing_subject_single_run tutorial to get a bit more\nfamiliar with the base concepts, and only then run thi script.\n\nTo run this example, you must launch IPython via ``ipython\n--matplotlib`` in a terminal, or use ``jupyter-notebook``.\n\n.. contents:: **Contents**\n    :local:\n    :depth: 1\n\n\"\"\"\n\nimport numpy as np\nimport pandas as pd\nfrom nilearn import plotting\n\nfrom nistats import datasets"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Retrieving the data\n-------------------\n\nWe use a so-called localizer dataset, which consists in a 5-minutes\nacquisition of a fast event-related dataset.\n\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "data = datasets.fetch_localizer_first_level()\nt_r = 2.4\nparadigm_file = data.paradigm\nevents= pd.read_csv(paradigm_file, sep=' ', header=None, index_col=None)\nevents.columns = ['session', 'trial_type', 'onset']\nfmri_img = data.epi_img"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Running a basic model\n---------------------\n\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "from nistats.first_level_model import FirstLevelModel\nfirst_level_model = FirstLevelModel(t_r)\nfirst_level_model = first_level_model.fit(fmri_img, events=events)\ndesign_matrix = first_level_model.design_matrices_[0]\n\nfrom nistats.reporting import plot_design_matrix\nplot_design_matrix(design_matrix)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Specify the contrasts.\n\nFor this, let's create a function that, given the deisgn matrix,\ngenerates the corresponding contrasts.\nThis will be useful\n\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "def make_localizer_contrasts(design matrix):\n    \"\"\" returns a dictionary of four contasts, given the design matrix\"\"\"\n    # first generate canonical contrasts \n    contrast_matrix = np.eye(design_matrix.shape[1])\n    contrasts = dict([(column, contrast_matrix[i])\n                      for i, column in enumerate(design_matrix.columns)])\n    # Add more complex contrasts\n    contrasts[\"audio\"] = contrasts[\"clicDaudio\"] + contrasts[\"clicGaudio\"] +\\\n                         contrasts[\"calculaudio\"] + contrasts[\"phraseaudio\"]\n    contrasts[\"video\"] = contrasts[\"clicDvideo\"] + contrasts[\"clicGvideo\"] + \\\n                         contrasts[\"calculvideo\"] + contrasts[\"phrasevideo\"]\n    contrasts[\"computation\"] = contrasts[\"calculaudio\"] + contrasts[\"calculvideo\"]\n    contrasts[\"sentences\"] = contrasts[\"phraseaudio\"] + contrasts[\"phrasevideo\"]\n\n    #########################################################################\n    # Short list of more relevant contrasts\n    contrasts = {\n        \"left-right\": (contrasts[\"clicGaudio\"] + contrasts[\"clicGvideo\"]\n                       - contrasts[\"clicDaudio\"] - contrasts[\"clicDvideo\"]),\n        \"H-V\": contrasts[\"damier_H\"] - contrasts[\"damier_V\"],\n        \"audio-video\": contrasts[\"audio\"] - contrasts[\"video\"],\n        \"computation-sentences\": (contrasts[\"computation\"] -\n                                  contrasts[\"sentences\"]),\n    }\n    return contrasts\n\ncontrasts = make_localizer_contrasts(design_matrix)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "contrast estimation\n\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "fig = plt.figure(figsize=(8, 2))\nfor index, (contrast_id, contrast_val) in enumerate(contrasts.items()):\n    ax = plt.subplot(1, len(contrasts), 1 + index)\n    z_map = first_level_model.compute_contrast(\n        contrast_val, output_type='z_score')\n    plotting.plot_stat_map(\n        z_map, display_mode='z', threshold=3.0, title=contrast_id, axes=ax,\n        cut_coords=1)\n\nplotting.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Null drift model\n\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "first_level_model = FirstLevelModel(t_r, drift_model=None)\nfirst_level_model = first_level_model.fit(fmri_img, events=events)\ndesign_matrix = first_level_model.design_matrices_[0]\nplot_design_matrix(design_matrix)\ncontrasts = make_localizer_contrasts(design_matrix)\nfig = plt.figure(figsize=(8, 2))\nfor index, (contrast_id, contrast_val) in enumerate(contrasts.items()):\n    ax = plt.subplot(1, len(contrasts), 1 + index)\n    z_map = first_level_model.compute_contrast(\n        contrast_val, output_type='z_score')\n    plotting.plot_stat_map(\n        z_map, display_mode='z', threshold=3.0, title=contrast_id, axes=ax,\n        cut_coords=1)\n\nplotting.show()"
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.6.5"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}