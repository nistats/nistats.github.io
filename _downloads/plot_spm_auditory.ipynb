{
  "nbformat_minor": 0, 
  "nbformat": 4, 
  "cells": [
    {
      "execution_count": null, 
      "cell_type": "code", 
      "source": [
        "%matplotlib inline"
      ], 
      "outputs": [], 
      "metadata": {
        "collapsed": false
      }
    }, 
    {
      "source": [
        "\nUnivariate analysis of block design, one condition versus rest, single subject\n==============================================================================\n\nAuthors: Bertrand Thirion, dohmatob elvis dopgima, Christophe Pallier, 2015--2017\n\n\n\nIn this tutorial, we compare the fMRI signal during periods of auditory stimulation\nversus periods of rest, using a General Linear Model (GLM). We will\nuse a univariate approach in which independent tests are performed at\neach single-voxel.\n\nThe dataset comes from experiment conducted at the FIL by Geriant Rees\nunder the direction of Karl Friston. It is provided by FIL methods\ngroup which develops the SPM software.\n\nAccording to SPM documentation, 96 acquisitions were made (RT=7s), in\nblocks of 6, giving 16 42s blocks. The condition for successive blocks\nalternated between rest and auditory stimulation, starting with rest.\nAuditory stimulation was bi-syllabic words presented binaurally at a\nrate of 60 per minute. The functional data starts at acquisiton 4,\nimage fM00223_004.\n\nThe whole brain BOLD/EPI images were acquired on a modified 2T Siemens\nMAGNETOM Vision system. Each acquisition consisted of 64 contiguous\nslices (64x64x64 3mm x 3mm x 3mm voxels). Acquisition took 6.05s, with\nthe scan to scan repeat time (RT) set arbitrarily to 7s.\n\n\nThis analyse described here is performed in the native space, on the\noriginal EPI scans without any spatial or temporal preprocessing.\n(More sensitive results would likely be obtained on the corrected,\nspatially normalized and smoothed images).\n\n\nTo run this example, you must launch IPython via ``ipython\n--matplotlib`` in a terminal, or use the Jupyter notebook.\n    :depth: 1\n\n\n"
      ], 
      "cell_type": "markdown", 
      "metadata": {}
    }, 
    {
      "source": [
        "Retrieving the data\n-------------------\n\n<div class=\"alert alert-info\"><h4>Note</h4><p>In this tutorial, we load the data using a data downloading\n          function.To input your own data, you will need to pass\n          a list of paths to your own files.</p></div>\n\n"
      ], 
      "cell_type": "markdown", 
      "metadata": {}
    }, 
    {
      "execution_count": null, 
      "cell_type": "code", 
      "source": [
        "from nistats.datasets import fetch_spm_auditory\nsubject_data = fetch_spm_auditory()"
      ], 
      "outputs": [], 
      "metadata": {
        "collapsed": false
      }
    }, 
    {
      "source": [
        "We can list the filenames of the functional images\n\n"
      ], 
      "cell_type": "markdown", 
      "metadata": {}
    }, 
    {
      "execution_count": null, 
      "cell_type": "code", 
      "source": [
        "print(subject_data.func)"
      ], 
      "outputs": [], 
      "metadata": {
        "collapsed": false
      }
    }, 
    {
      "source": [
        "Display the first functional image:\n\n"
      ], 
      "cell_type": "markdown", 
      "metadata": {}
    }, 
    {
      "execution_count": null, 
      "cell_type": "code", 
      "source": [
        "from nilearn.plotting import plot_stat_map, plot_anat, plot_img\nplot_img(subject_data.func[0])"
      ], 
      "outputs": [], 
      "metadata": {
        "collapsed": false
      }
    }, 
    {
      "source": [
        "Display the subject's anatomical image:\n\n"
      ], 
      "cell_type": "markdown", 
      "metadata": {}
    }, 
    {
      "execution_count": null, 
      "cell_type": "code", 
      "source": [
        "plot_anat(subject_data.anat)"
      ], 
      "outputs": [], 
      "metadata": {
        "collapsed": false
      }
    }, 
    {
      "source": [
        "Next, we concatenate all the 3D EPI image into a single 4D image:\n\n"
      ], 
      "cell_type": "markdown", 
      "metadata": {}
    }, 
    {
      "execution_count": null, 
      "cell_type": "code", 
      "source": [
        "from nilearn.image import concat_imgs\nfmri_img = concat_imgs(subject_data.func)"
      ], 
      "outputs": [], 
      "metadata": {
        "collapsed": false
      }
    }, 
    {
      "source": [
        "And we average all the EPI images in order to create a background\nimage that will be used to display the activations:\n\n"
      ], 
      "cell_type": "markdown", 
      "metadata": {}
    }, 
    {
      "execution_count": null, 
      "cell_type": "code", 
      "source": [
        "from nilearn import image\nmean_img = image.mean_img(fmri_img)"
      ], 
      "outputs": [], 
      "metadata": {
        "collapsed": false
      }
    }, 
    {
      "source": [
        "Specifying the experimental paradigm\n------------------------------------\n\nWe must provide a description of the experiment, that is, define the\ntiming of the auditory stimulation and rest periods. According to\nthe documentation of the dataset, there were 16 42s blocks --- in\nwhich 6 scans were acquired --- alternating between rest and\nauditory stimulation, starting with rest. We use standard python\nfunctions to create a pandas.DataFrame object that specifies the\ntimings:\n\n"
      ], 
      "cell_type": "markdown", 
      "metadata": {}
    }, 
    {
      "execution_count": null, 
      "cell_type": "code", 
      "source": [
        "import numpy as np\ntr = 7.\nslice_time_ref = 0.\nn_scans = 96\nepoch_duration = 6 * tr  # duration in seconds\nconditions = ['rest', 'active'] * 8\nn_blocks = len(conditions)\nduration = epoch_duration * np.ones(n_blocks)\nonset = np.linspace(0, (n_blocks - 1) * epoch_duration, n_blocks)\n\nimport pandas as pd\nevents = pd.DataFrame({'onset': onset, 'duration': duration, 'trial_type': conditions})"
      ], 
      "outputs": [], 
      "metadata": {
        "collapsed": false
      }
    }, 
    {
      "source": [
        "The ``events`` object contains the information for the design:\n\n"
      ], 
      "cell_type": "markdown", 
      "metadata": {}
    }, 
    {
      "execution_count": null, 
      "cell_type": "code", 
      "source": [
        "print(events)"
      ], 
      "outputs": [], 
      "metadata": {
        "collapsed": false
      }
    }, 
    {
      "source": [
        "Performing the GLM analysis\n---------------------------\n\nWe need to construct a *design matrix* using the timing information\nprovided by the ``events`` object. The design matrix contains\nregressors of interest as well as regressors of non-interest\nmodeling temporal drifts:\n\n"
      ], 
      "cell_type": "markdown", 
      "metadata": {}
    }, 
    {
      "execution_count": null, 
      "cell_type": "code", 
      "source": [
        "frame_times = np.linspace(0, (n_scans - 1) * tr, n_scans)\ndrift_model = 'Cosine'\nperiod_cut = 4. * epoch_duration\nhrf_model = 'glover + derivative'"
      ], 
      "outputs": [], 
      "metadata": {
        "collapsed": false
      }
    }, 
    {
      "source": [
        "It is now time to create a ``FirstLevelModel`` object\nand fit it to the 4D dataset:\n\n"
      ], 
      "cell_type": "markdown", 
      "metadata": {}
    }, 
    {
      "execution_count": null, 
      "cell_type": "code", 
      "source": [
        "from nistats.first_level_model import FirstLevelModel\n\nfmri_glm = FirstLevelModel(tr, slice_time_ref, noise_model='ar1',\n                           standardize=False, hrf_model=hrf_model,\n                           drift_model=drift_model, period_cut=period_cut)\nfmri_glm = fmri_glm.fit(fmri_img, events)"
      ], 
      "outputs": [], 
      "metadata": {
        "collapsed": false
      }
    }, 
    {
      "source": [
        "One can inspect the design matrix (rows represent time, and\ncolumns contain the predictors):\n\n"
      ], 
      "cell_type": "markdown", 
      "metadata": {}
    }, 
    {
      "execution_count": null, 
      "cell_type": "code", 
      "source": [
        "from nistats.reporting import plot_design_matrix\ndesign_matrix = fmri_glm.design_matrices_[0]\nplot_design_matrix(design_matrix)"
      ], 
      "outputs": [], 
      "metadata": {
        "collapsed": false
      }
    }, 
    {
      "source": [
        "The first column contains the expected reponse profile of regions which are\nsensitive to the auditory stimulation.\n\n"
      ], 
      "cell_type": "markdown", 
      "metadata": {}
    }, 
    {
      "execution_count": null, 
      "cell_type": "code", 
      "source": [
        "import matplotlib.pyplot as plt\nplt.plot(design_matrix['active'])\nplt.xlabel('scan')\nplt.title('Expected Auditory Response')\nplt.show()"
      ], 
      "outputs": [], 
      "metadata": {
        "collapsed": false
      }
    }, 
    {
      "source": [
        "Detecting voxels with significant effects\n-----------------------------------------\n\nTo access the estimated coefficients (Betas of the GLM model), we\ncreated constrasts with a single '1' in each of the columns:\n\n"
      ], 
      "cell_type": "markdown", 
      "metadata": {}
    }, 
    {
      "execution_count": null, 
      "cell_type": "code", 
      "source": [
        "contrast_matrix = np.eye(design_matrix.shape[1])\ncontrasts = dict([(column, contrast_matrix[i])\n                  for i, column in enumerate(design_matrix.columns)])\n\n\"\"\"\ncontrasts::\n\n  {\n  'active':            array([ 1.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.]),\n  'active_derivative': array([ 0.,  1.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.]),\n  'constant':          array([ 0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  1.]),\n  'drift_1':           array([ 0.,  0.,  0.,  0.,  1.,  0.,  0.,  0.,  0.,  0.,  0.,  0.]),\n  'drift_2':           array([ 0.,  0.,  0.,  0.,  0.,  1.,  0.,  0.,  0.,  0.,  0.,  0.]),\n  'drift_3':           array([ 0.,  0.,  0.,  0.,  0.,  0.,  1.,  0.,  0.,  0.,  0.,  0.]),\n  'drift_4':           array([ 0.,  0.,  0.,  0.,  0.,  0.,  0.,  1.,  0.,  0.,  0.,  0.]),\n  'drift_5':           array([ 0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  1.,  0.,  0.,  0.]),\n  'drift_6':           array([ 0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  1.,  0.,  0.]),\n  'drift_7':           array([ 0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  1.,  0.]),\n  'rest':              array([ 0.,  0.,  1.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.]),\n  'rest_derivative':   array([ 0.,  0.,  0.,  1.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.])}\n\"\"\""
      ], 
      "outputs": [], 
      "metadata": {
        "collapsed": false
      }
    }, 
    {
      "source": [
        "We can then compare the two conditions 'active' and 'rest' by\ngenerating the relevant contrast:\n\n"
      ], 
      "cell_type": "markdown", 
      "metadata": {}
    }, 
    {
      "execution_count": null, 
      "cell_type": "code", 
      "source": [
        "active_minus_rest =  contrasts['active'] - contrasts['rest']\n\neff_map = fmri_glm.compute_contrast(active_minus_rest,\n                                    output_type='effect_size')\n\nz_map = fmri_glm.compute_contrast(active_minus_rest,\n                                  output_type='z_score')"
      ], 
      "outputs": [], 
      "metadata": {
        "collapsed": false
      }
    }, 
    {
      "source": [
        "Plot thresholded z scores map\n\n"
      ], 
      "cell_type": "markdown", 
      "metadata": {}
    }, 
    {
      "execution_count": null, 
      "cell_type": "code", 
      "source": [
        "plot_stat_map(z_map, bg_img=mean_img, threshold=3.0,\n              display_mode='z', cut_coords=3, black_bg=True,\n              title='Active minus Rest (Z>3)')"
      ], 
      "outputs": [], 
      "metadata": {
        "collapsed": false
      }
    }, 
    {
      "source": [
        "We can use ``nibabel.save`` to save the effect and zscore maps to the disk\n\n"
      ], 
      "cell_type": "markdown", 
      "metadata": {}
    }, 
    {
      "execution_count": null, 
      "cell_type": "code", 
      "source": [
        "import os\noutdir = 'results'\nif not os.path.exists(outdir):\n    os.mkdir(outdir)\n\nimport nibabel\nfrom os.path import join\nnibabel.save(z_map, join('results', 'active_vs_rest_z_map.nii'))\nnibabel.save(eff_map, join('results', 'active_vs_rest_eff_map.nii'))"
      ], 
      "outputs": [], 
      "metadata": {
        "collapsed": false
      }
    }, 
    {
      "source": [
        "Extract the signal from a voxels\n --------------------------------\n\nWe search for the voxel with the larger z-score and plot the signal\n(warning: double dipping!)\n\n"
      ], 
      "cell_type": "markdown", 
      "metadata": {}
    }, 
    {
      "execution_count": null, 
      "cell_type": "code", 
      "source": [
        "# Find the coordinates of the peak\n\nfrom nibabel.affines import apply_affine\nvalues = z_map.get_data()\ncoord_peaks = np.dstack(np.unravel_index(np.argsort(values.ravel()),\n                                         values.shape))[0, 0, :]\ncoord_mm = apply_affine(z_map.affine, coord_peaks)"
      ], 
      "outputs": [], 
      "metadata": {
        "collapsed": false
      }
    }, 
    {
      "source": [
        "We create a masker for the voxel (allowing us to detrend the signal)\nand extract the time course\n\n"
      ], 
      "cell_type": "markdown", 
      "metadata": {}
    }, 
    {
      "execution_count": null, 
      "cell_type": "code", 
      "source": [
        "from nilearn.input_data import NiftiSpheresMasker\nmask = NiftiSpheresMasker([coord_mm], radius=3,\n                          detrend=True, standardize=True,\n                          high_pass=None, low_pass=None, t_r=7.)\nsig = mask.fit_transform(fmri_img)"
      ], 
      "outputs": [], 
      "metadata": {
        "collapsed": false
      }
    }, 
    {
      "source": [
        "Let's plot the signal and the theoretical response\n\n"
      ], 
      "cell_type": "markdown", 
      "metadata": {}
    }, 
    {
      "execution_count": null, 
      "cell_type": "code", 
      "source": [
        "plt.plot(frame_times, sig, label='voxel %d %d %d' % tuple(coord_mm))\nplt.plot(design_matrix['active'], color='red', label='model')\nplt.xlabel('scan')\nplt.legend()\nplt.show()"
      ], 
      "outputs": [], 
      "metadata": {
        "collapsed": false
      }
    }
  ], 
  "metadata": {
    "kernelspec": {
      "display_name": "Python 2", 
      "name": "python2", 
      "language": "python"
    }, 
    "language_info": {
      "mimetype": "text/x-python", 
      "nbconvert_exporter": "python", 
      "name": "python", 
      "file_extension": ".py", 
      "version": "2.7.12", 
      "pygments_lexer": "ipython2", 
      "codemirror_mode": {
        "version": 2, 
        "name": "ipython"
      }
    }
  }
}