{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "%matplotlib inline"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "\nAnalysis of a single session, single subject fMRI dataset\n=========================================================\n\nIn this tutorial, we compare the fMRI signal during periods of auditory\nstimulation versus periods of rest, using a General Linear Model (GLM).\n\nThe dataset comes from an experiment conducted at the FIL by Geriant Rees\nunder the direction of Karl Friston. It is provided by FIL methods\ngroup which develops the SPM software.\n\nAccording to SPM documentation, 96 scans were acquired (repetition time TR=7s) in one session. The paradigm consisted of alternating periods of stimulation and rest, lasting 42s each (that is, for 6 scans). The sesssion started with a rest block.\nAuditory stimulation consisted of bi-syllabic words presented binaurally at a\nrate of 60 per minute. The functional data starts at scan number 4, that is the \nimage file ``fM00223_004``.\n\nThe whole brain BOLD/EPI images were acquired on a  2T Siemens\nMAGNETOM Vision system. Each scan consisted of 64 contiguous\nslices (64x64x64 3mm x 3mm x 3mm voxels). Acquisition of one scan took 6.05s, with the scan to scan repeat time (TR) set arbitrarily to 7s.\n\nThe analyse described here is performed in the native space, directly on the\noriginal EPI scans without any spatial or temporal preprocessing.\n(More sensitive results would likely be obtained on the corrected,\nspatially normalized and smoothed images).\n\n\nTo run this example, you must launch IPython via ``ipython\n--matplotlib`` in a terminal, or use ``jupyter-notebook``.\n    :depth: 1\n\n\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Retrieving the data\n-------------------\n\n<div class=\"alert alert-info\"><h4>Note</h4><p>In this tutorial, we load the data using a data downloading\n          function. To input your own data, you will need to provide\n          a list of paths to your own files in the ``subject_data`` variable.</p></div>\n\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "from nistats.datasets import fetch_spm_auditory\nsubject_data = fetch_spm_auditory()\nprint(subject_data.func)  # print the list of names of functional images"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "We can display the first functional image and the subject's anatomy:\n\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "from nilearn.plotting import plot_stat_map, plot_anat, plot_img, show\nimport matplotlib.pyplot as plt\nplot_img(subject_data.func[0])\nplt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "and now the subject's anatomy\n\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "plot_anat(subject_data.anat)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Next, we concatenate all the 3D EPI image into a single 4D image,\nthe we average them in order to create a background\nimage that will be used to display the activations:\n\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "from nilearn.image import concat_imgs, mean_img\nfmri_img = concat_imgs(subject_data.func)\nmean_img = mean_img(fmri_img)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Specifying the experimental paradigm\n------------------------------------\n\nWe must provide now a description of the experiment, that is, define the\ntiming of the auditory stimulation and rest periods. According to\nthe documentation of the dataset, there were sixteen 42s-long blocks --- in\nwhich 6 scans were acquired --- alternating between rest and\nauditory stimulation, starting with rest.\n\nThe following table provide all the relevant informations:\n\n\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "\"\"\"\nduration,  onset,  trial_type\n    42  ,    0  ,  rest\n    42  ,   42  ,  active\n    42  ,   84  ,  rest\n    42  ,  126  ,  active\n    42  ,  168  ,  rest\n    42  ,  210  ,  active\n    42  ,  252  ,  rest\n    42  ,  294  ,  active\n    42  ,  336  ,  rest\n    42  ,  378  ,  active\n    42  ,  420  ,  rest\n    42  ,  462  ,  active\n    42  ,  504  ,  rest\n    42  ,  546  ,  active\n    42  ,  588  ,  rest\n    42  ,  630  ,  active\n\"\"\"\n\n# We can read such a table from a spreadsheet file  created with OpenOffice Calcor Office Excel, and saved under the *comma separated values* format (``.csv``). \nimport pandas as pd\nevents = pd.read_csv('auditory_block_paradigm.csv')\nprint(events)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Performing the GLM analysis\n---------------------------\n\nIt is now time to create and estimate a ``FirstLevelModel`` object, which will# generate the *design matrix* using the  information provided by the ``events` object.\n\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "from nistats.first_level_model import FirstLevelModel"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "t_r=7(s) is the time of repetition of acquisitions\nnoise_model='ar1' specifies the noise covariance model: a lag-1 dependence\nstandardize=False means that we do not want to rescale the time\nseries to mean 0, variance 1\nhrf_model='spm' means that we rely on the SPM \"canonical hrf\" model\n(without time or dispersion derivatives)\ndrift_model='cosine' means that we model the signal drifts as slow\noscillating time functions\nperiod\u00e8cut=160(s) defines the cutoff frequency (its inverse actually).\n\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "fmri_glm = FirstLevelModel(t_r=7,\n                           noise_model='ar1',\n                           standardize=False,\n                           hrf_model='spm',\n                           drift_model='cosine',\n                           period_cut=160)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Now that we have specified the mdoel, we can run it on the fMRI image\n\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "fmri_glm = fmri_glm.fit(fmri_img, events)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "One can inspect the design matrix (rows represent time, and\ncolumns contain the predictors):\n\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "from nistats.reporting import plot_design_matrix\ndesign_matrix = fmri_glm.design_matrices_[0]"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "We have taken the first design matrix, because the model is meant\nfor multiple runs\n\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "plot_design_matrix(design_matrix)\nplt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "The first column contains the expected reponse profile of regions which are\nsensitive to the auditory stimulation.\nLet's plot this first column\n\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "plt.plot(design_matrix['active'])\nplt.xlabel('scan')\nplt.title('Expected Auditory Response')\nplt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Detecting voxels with significant effects\n-----------------------------------------\n\nTo access the estimated coefficients (Betas of the GLM model), we\ncreated constrast with a single '1' in each of the columns: The role of the contrast is to select some columns of the model --and potentially weight them-- to study the associated statistics. So in a nutshell, a contrast is a linear combination of the estimated effects\nHere we can define canonical contrasts that just consider the two condition in isolation, let's call them \"conditions\", then a contrast that makes the difference between these conditions.\n\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "from numpy import array\nconditions = {\n    'active': array([1., 0., 0., 0., 0., 0., 0., 0., 0., 0.]),\n    'rest':   array([0., 1., 0., 0., 0., 0., 0., 0., 0., 0.]),\n}"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "We can then compare the two conditions 'active' and 'rest' by\ngenerating the relevant contrast:\n\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "active_minus_rest = conditions['active'] - conditions['rest']"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "this is the estimated effect. It is in BOLD signal unit, but has no statistical guarantees, because it does not take into account the associated variance\n\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "eff_map = fmri_glm.compute_contrast(active_minus_rest,\n                                    output_type='effect_size')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "In order to get statistical significance, we form a t-statistic, and directly convert is into z-scale.\n\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "z_map = fmri_glm.compute_contrast(active_minus_rest,\n                                  output_type='z_score')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Plot thresholded z scores map\nwe display it on top of the average functional image of the seris (could be the anatomical image of the subject).\nwe use arbitrarily a threshold of 3.0 in z-scale. We'll see later how to use corrected thresholds.\nwe show to display 3 axial views: display_mode='z', cut_coords=3\n\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "plot_stat_map(z_map, bg_img=mean_img, threshold=3.0,\n              display_mode='z', cut_coords=3, black_bg=True,\n              title='Active minus Rest (Z>3)')\nplt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "We can save the effect and zscore maps to the disk\nfirst create a directory where you want tow rite the images\n\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "import os\noutdir = 'results'\nif not os.path.exists(outdir):\n    os.mkdir(outdir)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Then save the images in this directory\n\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "from os.path import join\nz_map.to_filename(join('results', 'active_vs_rest_z_map.nii.gz'))\neff_map.to_filename(join('results', 'active_vs_rest_eff_map.nii.gz'))"
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.6.5"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}