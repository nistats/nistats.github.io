
<!DOCTYPE html>

<html xmlns="http://www.w3.org/1999/xhtml" lang="en">
  <head>
    <meta charset="utf-8" />
    <title>Nistats: Functional MRI in Python &#8212; functional MRI for NeuroImaging</title>
    <link rel="stylesheet" href="../../_static/nature.css" type="text/css" />
    <link rel="stylesheet" href="../../_static/pygments.css" type="text/css" />
    <link rel="stylesheet" type="text/css" href="../../_static/gallery.css" />
    <script type="text/javascript" id="documentation_options" data-url_root="../../" src="../../_static/documentation_options.js"></script>
    <script type="text/javascript" src="../../_static/jquery.js"></script>
    <script type="text/javascript" src="../../_static/underscore.js"></script>
    <script type="text/javascript" src="../../_static/doctools.js"></script>
    <script type="text/javascript" src="../../_static/language_data.js"></script>
    <script type="text/javascript" src="../../_static/copybutton.js"></script>
    <link rel="shortcut icon" href="../../_static/favicon.ico"/>
    <link rel="search" title="Search" href="../../search.html" />
    <link rel="next" title="2.1.2. Studying first-level-model details in a trials-and-error fashion" href="plot_first_level_model_details.html" />
    <link rel="prev" title="2. Nistats usage examples" href="../index.html" />
<meta content="True" name="HandheldFriendly">
<meta name="viewport" content="width=device-width, initial-scale=1.0, maximum-scale=1.0, user-scalable=0">
<meta name="keywords" content="nistats, neuroimaging, python, neuroscience, statistics">
<script type="text/javascript">
$(function () {
    // Lock the table of content to a fixed position once we scroll enough
    var top = 105 + $('.sphinxsidebarwrapper').offset().top - parseFloat($('.sphinxsidebarwrapper').css('margin-top').replace(/auto/, 0)),
        sections = {},
        i        = 0,
	url	 = document.URL.replace(/#.*$/, ""),
	current_section = 0;

    // Grab positions of our sections
    $('.headerlink').each(function(){
        sections[this.href.replace(url, '')] = $(this).offset().top - 50;
    });

    $(window).scroll(function(event) {
	var pos   = $(window).scrollTop();
	// Lock the table of content to a fixed position once we scroll enough
	if(pos > top){
	    //begin to scroll
	    $('.sphinxsidebarwrapper').css("position", "fixed");
	    $('.sphinxsidebarwrapper').css("top", -105);
	}
	else{
	    //lock it back into place
	    $('.sphinxsidebarwrapper').css("position", "relative");
	    $('.sphinxsidebarwrapper').css("top",0);
	}

	// Highlight the current section
	$('a.internal').removeClass('active');
        for(i in sections){
            if(sections[i] > pos){
		break;
            };
	    if($('a.internal[href$="' + i + '"]').is(':visible')){
		current_section = i;
	    };
        }
	$('a.internal[href$="' + current_section + '"]').addClass('active');
    });

});
</script>


<script type="text/javascript">

        var _gaq = _gaq || [];
        _gaq.push(['_setAccount', 'UA-41920728-1']);
        _gaq.push(['_trackPageview']);

        (function() {
            var ga = document.createElement('script'); ga.type = 'text/javascript'; ga.async = true;
            ga.src = ('https:' == document.location.protocol ? 'https://ssl' : 'http://www') + '.google-analytics.com/ga.js';
            var s = document.getElementsByTagName('script')[0]; s.parentNode.insertBefore(ga, s);
        })();
    </script>

  </head><body>
<div id="logo-banner">
  <div class="logo">
    <a href="../../index.html">
      <img src="../../_static/nistats-logo.png" alt="Nistats logo"  border="0" />
    </a>
  </div>
  <!-- A tag cloud to make it easy for people to find what they are
                         looking for -->
 <div class="tags">
  <ul>
    <li>
      <big><a href="../04_low_level_functions/plot_hrf.html">HRF</a></big>
    </li>
    <li>
      <small><a href="../04_low_level_functions/plot_design_matrix.html">Design Matrix</a></small>
    </li>
    <li>
      <small><a href="../02_first_level_models/plot_localizer_analysis.html">First Level</a></small>
    </li>
    <li>
      <big><a href="../03_second_level_models/plot_thresholding.html">Second Level</a></big>
    </li>
    <li>
      <big><a href="plot_bids_analysis.html">BIDS datasets</a></big>
    </li>
  </ul>
 </div>

  <div class="banner">
    <h1>Nistats:</h1>
    <h2>Functional MRI Neuro-Imaging in Python</h2>
  </div>
  <div class="search_form">
    <div id="cse" style="width: 100%;"></div>
    <script src="http://www.google.com/jsapi" type="text/javascript"></script>
    <script type="text/javascript">
      google.load('search', '1', {language : 'en'});
      google.setOnLoadCallback(function() {
      var customSearchControl = new google.search.CustomSearchControl('014136483057745874622:r-npolb1uki');
      customSearchControl.setResultSetSize(google.search.Search.FILTERED_CSE_RESULTSET);
      var options = new google.search.DrawOptions();
      options.setAutoComplete(true);
      customSearchControl.draw('cse', options);
      }, true);
    </script>
  </div>
</div>



    <div class="related" role="navigation" aria-label="related navigation">
      <h3>Navigation</h3>
      <ul>
        <li class="right" style="margin-right: 10px">
          <a href="../../py-modindex.html" title="Python Module Index"
             >modules</a></li>
        <li class="right" >
          <a href="plot_first_level_model_details.html" title="2.1.2. Studying first-level-model details in a trials-and-error fashion"
             accesskey="N">next</a> |</li>
        <li class="right" >
          <a href="../index.html" title="2. Nistats usage examples"
             accesskey="P">previous</a> |</li>
<li><a href="../../index.html">Nistats Home</a> |&nbsp;</li>
<li><a href="../../user_guide.html">User Guide</a> |&nbsp;</li>
<li><a href="../index.html">Examples</a> |&nbsp;</li>
<li><a href="../../modules/reference.html">Reference</a> |&nbsp;</li>
<li id="navbar-about"><a href="../../authors.html">About</a>|&nbsp;</li>
<li id="navbar-ecosystem"><a href="http://www.nipy.org/">Nipy ecosystem</a></li>

          <li class="nav-item nav-item-1"><a href="../../user_guide.html" >User guide: table of contents</a> &#187;</li>
          <li class="nav-item nav-item-2"><a href="../index.html" accesskey="U">2. Nistats usage examples</a> &#187;</li> 
      </ul>
    </div>
      <div class="sphinxsidebar" role="navigation" aria-label="main navigation">
        <div class="sphinxsidebarwrapper">


<h4> Giving credit </h4>
  <ul class="simple">
    <li><p>Please consider <a href="../../authors.html#citing">citing the
                    papers</a>.</p></li>
  </ul>

  <h3><a href="../../index.html">Table of Contents</a></h3>
  <ul>
<li><a class="reference internal" href="#">2.1.1. Analysis of a single session, single subject fMRI dataset</a><ul>
<li><a class="reference internal" href="#retrieving-the-data">2.1.1.1. Retrieving the data</a></li>
<li><a class="reference internal" href="#specifying-the-experimental-paradigm">2.1.1.2. Specifying the experimental paradigm</a></li>
<li><a class="reference internal" href="#performing-the-glm-analysis">2.1.1.3. Performing the GLM analysis</a></li>
<li><a class="reference internal" href="#detecting-voxels-with-significant-effects">2.1.1.4. Detecting voxels with significant effects</a></li>
</ul>
</li>
</ul>

  <h4>Previous topic</h4>
  <p class="topless"><a href="../index.html"
                        title="previous chapter">2. Nistats usage examples</a></p>
  <h4>Next topic</h4>
  <p class="topless"><a href="plot_first_level_model_details.html"
                        title="next chapter">2.1.2. Studying first-level-model details in a trials-and-error fashion</a></p>
<div id="searchbox" style="display: none" role="search">
  <h3 id="searchlabel">Quick search</h3>
    <div class="searchformwrapper">
    <form class="search" action="../../search.html" method="get">
      <input type="text" name="q" aria-labelledby="searchlabel" />
      <input type="submit" value="Go" />
    </form>
    </div>
</div>
<script type="text/javascript">$('#searchbox').show(0);</script>
        </div>
      </div>

    <div class="document">
      <div class="documentwrapper">
        <div class="bodywrapper">
          <div class="body" role="main">
            
  <div class="sphx-glr-download-link-note admonition note">
<p class="admonition-title">Note</p>
<p>Click <a class="reference internal" href="#sphx-glr-download-auto-examples-01-tutorials-plot-single-subject-single-run-py"><span class="std std-ref">here</span></a> to download the full example code</p>
</div>
<div class="sphx-glr-example-title section" id="analysis-of-a-single-session-single-subject-fmri-dataset">
<span id="sphx-glr-auto-examples-01-tutorials-plot-single-subject-single-run-py"></span><h1>2.1.1. Analysis of a single session, single subject fMRI dataset<a class="headerlink" href="#analysis-of-a-single-session-single-subject-fmri-dataset" title="Permalink to this headline">¶</a></h1>
<p>In this tutorial, we compare the fMRI signal during periods of auditory
stimulation versus periods of rest, using a General Linear Model (GLM).</p>
<p>The dataset comes from an experiment conducted at the FIL by Geriant Rees
under the direction of Karl Friston. It is provided by FIL methods
group which develops the SPM software.</p>
<p>According to SPM documentation, 96 scans were acquired (repetition time TR=7s) in one session. The paradigm consisted of alternating periods of stimulation and rest, lasting 42s each (that is, for 6 scans). The sesssion started with a rest block.
Auditory stimulation consisted of bi-syllabic words presented binaurally at a
rate of 60 per minute. The functional data starts at scan number 4, that is the
image file <code class="docutils literal notranslate"><span class="pre">fM00223_004</span></code>.</p>
<p>The whole brain BOLD/EPI images were acquired on a  2T Siemens
MAGNETOM Vision system. Each scan consisted of 64 contiguous
slices (64x64x64 3mm x 3mm x 3mm voxels). Acquisition of one scan took 6.05s, with the scan to scan repeat time (TR) set arbitrarily to 7s.</p>
<p>The analyse described here is performed in the native space, directly on the
original EPI scans without any spatial or temporal preprocessing.
(More sensitive results would likely be obtained on the corrected,
spatially normalized and smoothed images).</p>
<p>To run this example, you must launch IPython via <code class="docutils literal notranslate"><span class="pre">ipython</span>
<span class="pre">--matplotlib</span></code> in a terminal, or use <code class="docutils literal notranslate"><span class="pre">jupyter-notebook</span></code>.</p>
<div class="contents local topic" id="contents">
<p class="topic-title first"><strong>Contents</strong></p>
<ul class="simple">
<li><p><a class="reference internal" href="#retrieving-the-data" id="id1">Retrieving the data</a></p></li>
<li><p><a class="reference internal" href="#specifying-the-experimental-paradigm" id="id2">Specifying the experimental paradigm</a></p></li>
<li><p><a class="reference internal" href="#performing-the-glm-analysis" id="id3">Performing the GLM analysis</a></p></li>
<li><p><a class="reference internal" href="#detecting-voxels-with-significant-effects" id="id4">Detecting voxels with significant effects</a></p></li>
</ul>
</div>
<div class="section" id="retrieving-the-data">
<h2><a class="toc-backref" href="#id1">2.1.1.1. Retrieving the data</a><a class="headerlink" href="#retrieving-the-data" title="Permalink to this headline">¶</a></h2>
<div class="admonition note">
<p class="admonition-title">Note</p>
<p>In this tutorial, we load the data using a data downloading
function. To input your own data, you will need to provide
a list of paths to your own files in the <code class="docutils literal notranslate"><span class="pre">subject_data</span></code> variable.
These should abide to the Brain Imaging Data Structure (BIDS)
organization.</p>
</div>
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span><span class="kn">from</span> <span class="nn">nistats.datasets</span> <span class="k">import</span> <a href="../../modules/generated/nistats.datasets.fetch_spm_auditory.html#nistats.datasets.fetch_spm_auditory" title="View documentation for nistats.datasets.fetch_spm_auditory"><span class="n">fetch_spm_auditory</span></a>
<span class="n">subject_data</span> <span class="o">=</span> <a href="../../modules/generated/nistats.datasets.fetch_spm_auditory.html#nistats.datasets.fetch_spm_auditory" title="View documentation for nistats.datasets.fetch_spm_auditory"><span class="n">fetch_spm_auditory</span></a><span class="p">()</span>
<span class="nb">print</span><span class="p">(</span><span class="n">subject_data</span><span class="o">.</span><span class="n">func</span><span class="p">)</span>  <span class="c1"># print the list of names of functional images</span>
</pre></div>
</div>
<p class="sphx-glr-script-out">Out:</p>
<div class="sphx-glr-script-out highlight-none notranslate"><div class="highlight"><pre><span></span>[&#39;/home/kshitij/nilearn_data/spm_auditory/sub001/fM00223/fM00223_004.img&#39;, &#39;/home/kshitij/nilearn_data/spm_auditory/sub001/fM00223/fM00223_005.img&#39;, &#39;/home/kshitij/nilearn_data/spm_auditory/sub001/fM00223/fM00223_006.img&#39;, &#39;/home/kshitij/nilearn_data/spm_auditory/sub001/fM00223/fM00223_007.img&#39;, &#39;/home/kshitij/nilearn_data/spm_auditory/sub001/fM00223/fM00223_008.img&#39;, &#39;/home/kshitij/nilearn_data/spm_auditory/sub001/fM00223/fM00223_009.img&#39;, &#39;/home/kshitij/nilearn_data/spm_auditory/sub001/fM00223/fM00223_010.img&#39;, &#39;/home/kshitij/nilearn_data/spm_auditory/sub001/fM00223/fM00223_011.img&#39;, &#39;/home/kshitij/nilearn_data/spm_auditory/sub001/fM00223/fM00223_012.img&#39;, &#39;/home/kshitij/nilearn_data/spm_auditory/sub001/fM00223/fM00223_013.img&#39;, &#39;/home/kshitij/nilearn_data/spm_auditory/sub001/fM00223/fM00223_014.img&#39;, &#39;/home/kshitij/nilearn_data/spm_auditory/sub001/fM00223/fM00223_015.img&#39;, &#39;/home/kshitij/nilearn_data/spm_auditory/sub001/fM00223/fM00223_016.img&#39;, &#39;/home/kshitij/nilearn_data/spm_auditory/sub001/fM00223/fM00223_017.img&#39;, &#39;/home/kshitij/nilearn_data/spm_auditory/sub001/fM00223/fM00223_018.img&#39;, &#39;/home/kshitij/nilearn_data/spm_auditory/sub001/fM00223/fM00223_019.img&#39;, &#39;/home/kshitij/nilearn_data/spm_auditory/sub001/fM00223/fM00223_020.img&#39;, &#39;/home/kshitij/nilearn_data/spm_auditory/sub001/fM00223/fM00223_021.img&#39;, &#39;/home/kshitij/nilearn_data/spm_auditory/sub001/fM00223/fM00223_022.img&#39;, &#39;/home/kshitij/nilearn_data/spm_auditory/sub001/fM00223/fM00223_023.img&#39;, &#39;/home/kshitij/nilearn_data/spm_auditory/sub001/fM00223/fM00223_024.img&#39;, &#39;/home/kshitij/nilearn_data/spm_auditory/sub001/fM00223/fM00223_025.img&#39;, &#39;/home/kshitij/nilearn_data/spm_auditory/sub001/fM00223/fM00223_026.img&#39;, &#39;/home/kshitij/nilearn_data/spm_auditory/sub001/fM00223/fM00223_027.img&#39;, &#39;/home/kshitij/nilearn_data/spm_auditory/sub001/fM00223/fM00223_028.img&#39;, &#39;/home/kshitij/nilearn_data/spm_auditory/sub001/fM00223/fM00223_029.img&#39;, &#39;/home/kshitij/nilearn_data/spm_auditory/sub001/fM00223/fM00223_030.img&#39;, &#39;/home/kshitij/nilearn_data/spm_auditory/sub001/fM00223/fM00223_031.img&#39;, &#39;/home/kshitij/nilearn_data/spm_auditory/sub001/fM00223/fM00223_032.img&#39;, &#39;/home/kshitij/nilearn_data/spm_auditory/sub001/fM00223/fM00223_033.img&#39;, &#39;/home/kshitij/nilearn_data/spm_auditory/sub001/fM00223/fM00223_034.img&#39;, &#39;/home/kshitij/nilearn_data/spm_auditory/sub001/fM00223/fM00223_035.img&#39;, &#39;/home/kshitij/nilearn_data/spm_auditory/sub001/fM00223/fM00223_036.img&#39;, &#39;/home/kshitij/nilearn_data/spm_auditory/sub001/fM00223/fM00223_037.img&#39;, &#39;/home/kshitij/nilearn_data/spm_auditory/sub001/fM00223/fM00223_038.img&#39;, &#39;/home/kshitij/nilearn_data/spm_auditory/sub001/fM00223/fM00223_039.img&#39;, &#39;/home/kshitij/nilearn_data/spm_auditory/sub001/fM00223/fM00223_040.img&#39;, &#39;/home/kshitij/nilearn_data/spm_auditory/sub001/fM00223/fM00223_041.img&#39;, &#39;/home/kshitij/nilearn_data/spm_auditory/sub001/fM00223/fM00223_042.img&#39;, &#39;/home/kshitij/nilearn_data/spm_auditory/sub001/fM00223/fM00223_043.img&#39;, &#39;/home/kshitij/nilearn_data/spm_auditory/sub001/fM00223/fM00223_044.img&#39;, &#39;/home/kshitij/nilearn_data/spm_auditory/sub001/fM00223/fM00223_045.img&#39;, &#39;/home/kshitij/nilearn_data/spm_auditory/sub001/fM00223/fM00223_046.img&#39;, &#39;/home/kshitij/nilearn_data/spm_auditory/sub001/fM00223/fM00223_047.img&#39;, &#39;/home/kshitij/nilearn_data/spm_auditory/sub001/fM00223/fM00223_048.img&#39;, &#39;/home/kshitij/nilearn_data/spm_auditory/sub001/fM00223/fM00223_049.img&#39;, &#39;/home/kshitij/nilearn_data/spm_auditory/sub001/fM00223/fM00223_050.img&#39;, &#39;/home/kshitij/nilearn_data/spm_auditory/sub001/fM00223/fM00223_051.img&#39;, &#39;/home/kshitij/nilearn_data/spm_auditory/sub001/fM00223/fM00223_052.img&#39;, &#39;/home/kshitij/nilearn_data/spm_auditory/sub001/fM00223/fM00223_053.img&#39;, &#39;/home/kshitij/nilearn_data/spm_auditory/sub001/fM00223/fM00223_054.img&#39;, &#39;/home/kshitij/nilearn_data/spm_auditory/sub001/fM00223/fM00223_055.img&#39;, &#39;/home/kshitij/nilearn_data/spm_auditory/sub001/fM00223/fM00223_056.img&#39;, &#39;/home/kshitij/nilearn_data/spm_auditory/sub001/fM00223/fM00223_057.img&#39;, &#39;/home/kshitij/nilearn_data/spm_auditory/sub001/fM00223/fM00223_058.img&#39;, &#39;/home/kshitij/nilearn_data/spm_auditory/sub001/fM00223/fM00223_059.img&#39;, &#39;/home/kshitij/nilearn_data/spm_auditory/sub001/fM00223/fM00223_060.img&#39;, &#39;/home/kshitij/nilearn_data/spm_auditory/sub001/fM00223/fM00223_061.img&#39;, &#39;/home/kshitij/nilearn_data/spm_auditory/sub001/fM00223/fM00223_062.img&#39;, &#39;/home/kshitij/nilearn_data/spm_auditory/sub001/fM00223/fM00223_063.img&#39;, &#39;/home/kshitij/nilearn_data/spm_auditory/sub001/fM00223/fM00223_064.img&#39;, &#39;/home/kshitij/nilearn_data/spm_auditory/sub001/fM00223/fM00223_065.img&#39;, &#39;/home/kshitij/nilearn_data/spm_auditory/sub001/fM00223/fM00223_066.img&#39;, &#39;/home/kshitij/nilearn_data/spm_auditory/sub001/fM00223/fM00223_067.img&#39;, &#39;/home/kshitij/nilearn_data/spm_auditory/sub001/fM00223/fM00223_068.img&#39;, &#39;/home/kshitij/nilearn_data/spm_auditory/sub001/fM00223/fM00223_069.img&#39;, &#39;/home/kshitij/nilearn_data/spm_auditory/sub001/fM00223/fM00223_070.img&#39;, &#39;/home/kshitij/nilearn_data/spm_auditory/sub001/fM00223/fM00223_071.img&#39;, &#39;/home/kshitij/nilearn_data/spm_auditory/sub001/fM00223/fM00223_072.img&#39;, &#39;/home/kshitij/nilearn_data/spm_auditory/sub001/fM00223/fM00223_073.img&#39;, &#39;/home/kshitij/nilearn_data/spm_auditory/sub001/fM00223/fM00223_074.img&#39;, &#39;/home/kshitij/nilearn_data/spm_auditory/sub001/fM00223/fM00223_075.img&#39;, &#39;/home/kshitij/nilearn_data/spm_auditory/sub001/fM00223/fM00223_076.img&#39;, &#39;/home/kshitij/nilearn_data/spm_auditory/sub001/fM00223/fM00223_077.img&#39;, &#39;/home/kshitij/nilearn_data/spm_auditory/sub001/fM00223/fM00223_078.img&#39;, &#39;/home/kshitij/nilearn_data/spm_auditory/sub001/fM00223/fM00223_079.img&#39;, &#39;/home/kshitij/nilearn_data/spm_auditory/sub001/fM00223/fM00223_080.img&#39;, &#39;/home/kshitij/nilearn_data/spm_auditory/sub001/fM00223/fM00223_081.img&#39;, &#39;/home/kshitij/nilearn_data/spm_auditory/sub001/fM00223/fM00223_082.img&#39;, &#39;/home/kshitij/nilearn_data/spm_auditory/sub001/fM00223/fM00223_083.img&#39;, &#39;/home/kshitij/nilearn_data/spm_auditory/sub001/fM00223/fM00223_084.img&#39;, &#39;/home/kshitij/nilearn_data/spm_auditory/sub001/fM00223/fM00223_085.img&#39;, &#39;/home/kshitij/nilearn_data/spm_auditory/sub001/fM00223/fM00223_086.img&#39;, &#39;/home/kshitij/nilearn_data/spm_auditory/sub001/fM00223/fM00223_087.img&#39;, &#39;/home/kshitij/nilearn_data/spm_auditory/sub001/fM00223/fM00223_088.img&#39;, &#39;/home/kshitij/nilearn_data/spm_auditory/sub001/fM00223/fM00223_089.img&#39;, &#39;/home/kshitij/nilearn_data/spm_auditory/sub001/fM00223/fM00223_090.img&#39;, &#39;/home/kshitij/nilearn_data/spm_auditory/sub001/fM00223/fM00223_091.img&#39;, &#39;/home/kshitij/nilearn_data/spm_auditory/sub001/fM00223/fM00223_092.img&#39;, &#39;/home/kshitij/nilearn_data/spm_auditory/sub001/fM00223/fM00223_093.img&#39;, &#39;/home/kshitij/nilearn_data/spm_auditory/sub001/fM00223/fM00223_094.img&#39;, &#39;/home/kshitij/nilearn_data/spm_auditory/sub001/fM00223/fM00223_095.img&#39;, &#39;/home/kshitij/nilearn_data/spm_auditory/sub001/fM00223/fM00223_096.img&#39;, &#39;/home/kshitij/nilearn_data/spm_auditory/sub001/fM00223/fM00223_097.img&#39;, &#39;/home/kshitij/nilearn_data/spm_auditory/sub001/fM00223/fM00223_098.img&#39;, &#39;/home/kshitij/nilearn_data/spm_auditory/sub001/fM00223/fM00223_099.img&#39;]
</pre></div>
</div>
<p>We can display the first functional image and the subject’s anatomy:</p>
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span><span class="kn">from</span> <span class="nn">nilearn.plotting</span> <span class="k">import</span> <a href="http://nilearn.github.io/modules/generated/nilearn.plotting.plot_stat_map.html#nilearn.plotting.plot_stat_map" title="View documentation for nilearn.plotting.plot_stat_map"><span class="n">plot_stat_map</span></a><span class="p">,</span> <a href="http://nilearn.github.io/modules/generated/nilearn.plotting.plot_anat.html#nilearn.plotting.plot_anat" title="View documentation for nilearn.plotting.plot_anat"><span class="n">plot_anat</span></a><span class="p">,</span> <a href="http://nilearn.github.io/modules/generated/nilearn.plotting.plot_img.html#nilearn.plotting.plot_img" title="View documentation for nilearn.plotting.plot_img"><span class="n">plot_img</span></a><span class="p">,</span> <span class="n">show</span>
<a href="http://nilearn.github.io/modules/generated/nilearn.plotting.plot_img.html#nilearn.plotting.plot_img" title="View documentation for nilearn.plotting.plot_img"><span class="n">plot_img</span></a><span class="p">(</span><span class="n">subject_data</span><span class="o">.</span><span class="n">func</span><span class="p">[</span><span class="mi">0</span><span class="p">])</span>
<a href="http://nilearn.github.io/modules/generated/nilearn.plotting.plot_anat.html#nilearn.plotting.plot_anat" title="View documentation for nilearn.plotting.plot_anat"><span class="n">plot_anat</span></a><span class="p">(</span><span class="n">subject_data</span><span class="o">.</span><span class="n">anat</span><span class="p">)</span>
</pre></div>
</div>
<ul class="sphx-glr-horizontal">
<li><img alt="../../_images/sphx_glr_plot_single_subject_single_run_001.png" class="sphx-glr-multi-img" src="../../_images/sphx_glr_plot_single_subject_single_run_001.png" />
</li>
<li><img alt="../../_images/sphx_glr_plot_single_subject_single_run_002.png" class="sphx-glr-multi-img" src="../../_images/sphx_glr_plot_single_subject_single_run_002.png" />
</li>
</ul>
<p class="sphx-glr-script-out">Out:</p>
<div class="sphx-glr-script-out highlight-none notranslate"><div class="highlight"><pre><span></span>/home/kshitij/.programs/anaconda3/envs/nistats-py36-latest/lib/python3.6/site-packages/scipy/ndimage/measurements.py:272: DeprecationWarning: In future, it will be an error for &#39;np.bool_&#39; scalars to be interpreted as an index
  return _nd_image.find_objects(input, max_label)
</pre></div>
</div>
<p>Next, we concatenate all the 3D EPI image into a single 4D image,
then we average them in order to create a background
image that will be used to display the activations:</p>
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span><span class="kn">from</span> <span class="nn">nilearn.image</span> <span class="k">import</span> <a href="http://nilearn.github.io/modules/generated/nilearn.image.concat_imgs.html#nilearn.image.concat_imgs" title="View documentation for nilearn.image.concat_imgs"><span class="n">concat_imgs</span></a><span class="p">,</span> <a href="http://nilearn.github.io/modules/generated/nilearn.image.mean_img.html#nilearn.image.mean_img" title="View documentation for nilearn.image.mean_img"><span class="n">mean_img</span></a>
<span class="n">fmri_img</span> <span class="o">=</span> <a href="http://nilearn.github.io/modules/generated/nilearn.image.concat_imgs.html#nilearn.image.concat_imgs" title="View documentation for nilearn.image.concat_imgs"><span class="n">concat_imgs</span></a><span class="p">(</span><span class="n">subject_data</span><span class="o">.</span><span class="n">func</span><span class="p">)</span>
<a href="http://nilearn.github.io/modules/generated/nilearn.image.mean_img.html#nilearn.image.mean_img" title="View documentation for nilearn.image.mean_img"><span class="n">mean_img</span></a> <span class="o">=</span> <a href="http://nilearn.github.io/modules/generated/nilearn.image.mean_img.html#nilearn.image.mean_img" title="View documentation for nilearn.image.mean_img"><span class="n">mean_img</span></a><span class="p">(</span><span class="n">fmri_img</span><span class="p">)</span>
</pre></div>
</div>
</div>
<div class="section" id="specifying-the-experimental-paradigm">
<h2><a class="toc-backref" href="#id2">2.1.1.2. Specifying the experimental paradigm</a><a class="headerlink" href="#specifying-the-experimental-paradigm" title="Permalink to this headline">¶</a></h2>
<p>We must now provide a description of the experiment, that is, define the
timing of the auditory stimulation and rest periods. This is typically
provided in an events.tsv file. The path of this file is
provided in the dataset.</p>
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span><span class="kn">import</span> <span class="nn">pandas</span> <span class="k">as</span> <span class="nn">pd</span>
<span class="n">events</span> <span class="o">=</span> <a href="https://pandas.pydata.org/pandas-docs/stable/reference/api/pandas.read_table.html#pandas.read_table" title="View documentation for pandas.read_table"><span class="n">pd</span><span class="o">.</span><span class="n">read_table</span></a><span class="p">(</span><span class="n">subject_data</span><span class="p">[</span><span class="s1">&#39;events&#39;</span><span class="p">])</span>
<span class="nb">print</span><span class="p">(</span><span class="n">events</span><span class="p">)</span>
</pre></div>
</div>
<p class="sphx-glr-script-out">Out:</p>
<div class="sphx-glr-script-out highlight-none notranslate"><div class="highlight"><pre><span></span>    onset  duration trial_type
0     0.0      42.0       rest
1    42.0      42.0     active
2    84.0      42.0       rest
3   126.0      42.0     active
4   168.0      42.0       rest
5   210.0      42.0     active
6   252.0      42.0       rest
7   294.0      42.0     active
8   336.0      42.0       rest
9   378.0      42.0     active
10  420.0      42.0       rest
11  462.0      42.0     active
12  504.0      42.0       rest
13  546.0      42.0     active
14  588.0      42.0       rest
15  630.0      42.0     active
</pre></div>
</div>
</div>
<div class="section" id="performing-the-glm-analysis">
<h2><a class="toc-backref" href="#id3">2.1.1.3. Performing the GLM analysis</a><a class="headerlink" href="#performing-the-glm-analysis" title="Permalink to this headline">¶</a></h2>
<p>It is now time to create and estimate a <code class="docutils literal notranslate"><span class="pre">FirstLevelModel</span></code> object, that will generate the <em>design matrix</em> using the  information provided by the <code class="docutils literal notranslate"><span class="pre">events</span></code> object.</p>
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span><span class="kn">from</span> <span class="nn">nistats.first_level_model</span> <span class="k">import</span> <a href="../../modules/generated/nistats.first_level_model.FirstLevelModel.html#nistats.first_level_model.FirstLevelModel" title="View documentation for nistats.first_level_model.FirstLevelModel"><span class="n">FirstLevelModel</span></a>
</pre></div>
</div>
<p>Parameters of the first-level model</p>
<ul class="simple">
<li><p>t_r=7(s) is the time of repetition of acquisitions</p></li>
<li><p>noise_model=’ar1’ specifies the noise covariance model: a lag-1 dependence</p></li>
<li><p>standardize=False means that we do not want to rescale the time series to mean 0, variance 1</p></li>
<li><p>hrf_model=’spm’ means that we rely on the SPM “canonical hrf” model (without time or dispersion derivatives)</p></li>
<li><p>drift_model=’cosine’ means that we model the signal drifts as slow oscillating time functions</p></li>
<li><p>high_pass=0.01(Hz) defines the cutoff frequency (inverse of the time period).</p></li>
</ul>
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span><span class="n">fmri_glm</span> <span class="o">=</span> <a href="../../modules/generated/nistats.first_level_model.FirstLevelModel.html#nistats.first_level_model.FirstLevelModel" title="View documentation for nistats.first_level_model.FirstLevelModel"><span class="n">FirstLevelModel</span></a><span class="p">(</span><span class="n">t_r</span><span class="o">=</span><span class="mi">7</span><span class="p">,</span>
                           <span class="n">noise_model</span><span class="o">=</span><span class="s1">&#39;ar1&#39;</span><span class="p">,</span>
                           <span class="n">standardize</span><span class="o">=</span><span class="kc">False</span><span class="p">,</span>
                           <span class="n">hrf_model</span><span class="o">=</span><span class="s1">&#39;spm&#39;</span><span class="p">,</span>
                           <span class="n">drift_model</span><span class="o">=</span><span class="s1">&#39;cosine&#39;</span><span class="p">,</span>
                           <span class="n">high_pass</span><span class="o">=.</span><span class="mi">01</span><span class="p">)</span>
</pre></div>
</div>
<p>Now that we have specified the model, we can run it on the fMRI image</p>
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span><span class="n">fmri_glm</span> <span class="o">=</span> <span class="n">fmri_glm</span><span class="o">.</span><span class="n">fit</span><span class="p">(</span><span class="n">fmri_img</span><span class="p">,</span> <span class="n">events</span><span class="p">)</span>
</pre></div>
</div>
<p class="sphx-glr-script-out">Out:</p>
<div class="sphx-glr-script-out highlight-none notranslate"><div class="highlight"><pre><span></span>/home/kshitij/.programs/anaconda3/envs/nistats-py36-latest/lib/python3.6/site-packages/nilearn/_utils/cache_mixin.py:232: DeprecationWarning: The &#39;cachedir&#39; attribute has been deprecated in version 0.12 and will be removed in version 0.14.
Use os.path.join(memory.location, &#39;joblib&#39;) attribute instead.
  if (memory.cachedir is None and memory_level is not None
</pre></div>
</div>
<p>One can inspect the design matrix (rows represent time, and
columns contain the predictors).</p>
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span><span class="n">design_matrix</span> <span class="o">=</span> <span class="n">fmri_glm</span><span class="o">.</span><span class="n">design_matrices_</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span>
</pre></div>
</div>
<p>Formally, we have taken the first design matrix, because the model is
implictily meant to for multiple runs.</p>
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span><span class="kn">from</span> <span class="nn">nistats.reporting</span> <span class="k">import</span> <a href="../../modules/generated/nistats.reporting.plot_design_matrix.html#nistats.reporting.plot_design_matrix" title="View documentation for nistats.reporting.plot_design_matrix"><span class="n">plot_design_matrix</span></a>
<a href="../../modules/generated/nistats.reporting.plot_design_matrix.html#nistats.reporting.plot_design_matrix" title="View documentation for nistats.reporting.plot_design_matrix"><span class="n">plot_design_matrix</span></a><span class="p">(</span><span class="n">design_matrix</span><span class="p">)</span>
<span class="kn">import</span> <span class="nn">matplotlib.pyplot</span> <span class="k">as</span> <span class="nn">plt</span>
<a href="https://matplotlib.org/api/_as_gen/matplotlib.pyplot.show.html#matplotlib.pyplot.show" title="View documentation for matplotlib.pyplot.show"><span class="n">plt</span><span class="o">.</span><span class="n">show</span></a><span class="p">()</span>
</pre></div>
</div>
<img alt="../../_images/sphx_glr_plot_single_subject_single_run_003.png" class="sphx-glr-single-img" src="../../_images/sphx_glr_plot_single_subject_single_run_003.png" />
<p class="sphx-glr-script-out">Out:</p>
<div class="sphx-glr-script-out highlight-none notranslate"><div class="highlight"><pre><span></span>/home/kshitij/.programs/anaconda3/envs/nistats-py36-latest/lib/python3.6/site-packages/matplotlib/figure.py:445: UserWarning: Matplotlib is currently using agg, which is a non-GUI backend, so cannot show the figure.
  % get_backend())
</pre></div>
</div>
<p>Save the design matrix image to disk
first create a directory where you want to write the images</p>
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span><span class="kn">import</span> <span class="nn">os</span>
<span class="n">outdir</span> <span class="o">=</span> <span class="s1">&#39;results&#39;</span>
<span class="k">if</span> <span class="ow">not</span> <span class="n">os</span><span class="o">.</span><span class="n">path</span><span class="o">.</span><span class="n">exists</span><span class="p">(</span><span class="n">outdir</span><span class="p">):</span>
    <span class="n">os</span><span class="o">.</span><span class="n">mkdir</span><span class="p">(</span><span class="n">outdir</span><span class="p">)</span>

<span class="kn">from</span> <span class="nn">os.path</span> <span class="k">import</span> <span class="n">join</span>
<a href="../../modules/generated/nistats.reporting.plot_design_matrix.html#nistats.reporting.plot_design_matrix" title="View documentation for nistats.reporting.plot_design_matrix"><span class="n">plot_design_matrix</span></a><span class="p">(</span>
    <span class="n">design_matrix</span><span class="p">,</span> <span class="n">output_file</span><span class="o">=</span><span class="n">join</span><span class="p">(</span><span class="n">outdir</span><span class="p">,</span> <span class="s1">&#39;design_matrix.png&#39;</span><span class="p">))</span>
</pre></div>
</div>
<p>The first column contains the expected response profile of regions which are
sensitive to the auditory stimulation.
Let’s plot this first column</p>
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span><a href="https://matplotlib.org/api/_as_gen/matplotlib.pyplot.plot.html#matplotlib.pyplot.plot" title="View documentation for matplotlib.pyplot.plot"><span class="n">plt</span><span class="o">.</span><span class="n">plot</span></a><span class="p">(</span><span class="n">design_matrix</span><span class="p">[</span><span class="s1">&#39;active&#39;</span><span class="p">])</span>
<a href="https://matplotlib.org/api/_as_gen/matplotlib.pyplot.xlabel.html#matplotlib.pyplot.xlabel" title="View documentation for matplotlib.pyplot.xlabel"><span class="n">plt</span><span class="o">.</span><span class="n">xlabel</span></a><span class="p">(</span><span class="s1">&#39;scan&#39;</span><span class="p">)</span>
<a href="https://matplotlib.org/api/_as_gen/matplotlib.pyplot.title.html#matplotlib.pyplot.title" title="View documentation for matplotlib.pyplot.title"><span class="n">plt</span><span class="o">.</span><span class="n">title</span></a><span class="p">(</span><span class="s1">&#39;Expected Auditory Response&#39;</span><span class="p">)</span>
<a href="https://matplotlib.org/api/_as_gen/matplotlib.pyplot.show.html#matplotlib.pyplot.show" title="View documentation for matplotlib.pyplot.show"><span class="n">plt</span><span class="o">.</span><span class="n">show</span></a><span class="p">()</span>
</pre></div>
</div>
<img alt="../../_images/sphx_glr_plot_single_subject_single_run_004.png" class="sphx-glr-single-img" src="../../_images/sphx_glr_plot_single_subject_single_run_004.png" />
</div>
<div class="section" id="detecting-voxels-with-significant-effects">
<h2><a class="toc-backref" href="#id4">2.1.1.4. Detecting voxels with significant effects</a><a class="headerlink" href="#detecting-voxels-with-significant-effects" title="Permalink to this headline">¶</a></h2>
<p>To access the estimated coefficients (Betas of the GLM model), we
created contrast with a single ‘1’ in each of the columns: The role
of the contrast is to select some columns of the model –and
potentially weight them– to study the associated statistics. So in
a nutshell, a contrast is a weighted combination of the estimated
effects.  Here we can define canonical contrasts that just consider
the two condition in isolation —let’s call them “conditions”—
then a contrast that makes the difference between these conditions.</p>
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span><span class="kn">from</span> <span class="nn">numpy</span> <span class="k">import</span> <a href="https://docs.scipy.org/doc/numpy/reference/generated/numpy.array.html#numpy.array" title="View documentation for numpy.array"><span class="n">array</span></a>
<span class="n">conditions</span> <span class="o">=</span> <span class="p">{</span>
    <span class="s1">&#39;active&#39;</span><span class="p">:</span> <a href="https://docs.scipy.org/doc/numpy/reference/generated/numpy.array.html#numpy.array" title="View documentation for numpy.array"><span class="n">array</span></a><span class="p">([</span><span class="mf">1.</span><span class="p">,</span> <span class="mf">0.</span><span class="p">,</span> <span class="mf">0.</span><span class="p">,</span> <span class="mf">0.</span><span class="p">,</span> <span class="mf">0.</span><span class="p">,</span> <span class="mf">0.</span><span class="p">,</span> <span class="mf">0.</span><span class="p">,</span> <span class="mf">0.</span><span class="p">,</span> <span class="mf">0.</span><span class="p">,</span> <span class="mf">0.</span><span class="p">,</span> <span class="mf">0.</span><span class="p">,</span> <span class="mf">0.</span><span class="p">,</span> <span class="mf">0.</span><span class="p">,</span> <span class="mf">0.</span><span class="p">,</span> <span class="mf">0.</span><span class="p">,</span>
                     <span class="mf">0.</span><span class="p">]),</span>
    <span class="s1">&#39;rest&#39;</span><span class="p">:</span>   <a href="https://docs.scipy.org/doc/numpy/reference/generated/numpy.array.html#numpy.array" title="View documentation for numpy.array"><span class="n">array</span></a><span class="p">([</span><span class="mf">0.</span><span class="p">,</span> <span class="mf">1.</span><span class="p">,</span> <span class="mf">0.</span><span class="p">,</span> <span class="mf">0.</span><span class="p">,</span> <span class="mf">0.</span><span class="p">,</span> <span class="mf">0.</span><span class="p">,</span> <span class="mf">0.</span><span class="p">,</span> <span class="mf">0.</span><span class="p">,</span> <span class="mf">0.</span><span class="p">,</span> <span class="mf">0.</span><span class="p">,</span> <span class="mf">0.</span><span class="p">,</span> <span class="mf">0.</span><span class="p">,</span> <span class="mf">0.</span><span class="p">,</span> <span class="mf">0.</span><span class="p">,</span> <span class="mf">0.</span><span class="p">,</span>
                     <span class="mf">0.</span><span class="p">]),</span>
<span class="p">}</span>
</pre></div>
</div>
<p>We can then compare the two conditions ‘active’ and ‘rest’ by
defining the corresponding contrast:</p>
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span><span class="n">active_minus_rest</span> <span class="o">=</span> <span class="n">conditions</span><span class="p">[</span><span class="s1">&#39;active&#39;</span><span class="p">]</span> <span class="o">-</span> <span class="n">conditions</span><span class="p">[</span><span class="s1">&#39;rest&#39;</span><span class="p">]</span>
</pre></div>
</div>
<p>Let’s look at it: plot the coefficients of the contrast, indexed by
the names of the columns of the design matrix.</p>
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span><span class="kn">from</span> <span class="nn">nistats.reporting</span> <span class="k">import</span> <a href="../../modules/generated/nistats.reporting.plot_contrast_matrix.html#nistats.reporting.plot_contrast_matrix" title="View documentation for nistats.reporting.plot_contrast_matrix"><span class="n">plot_contrast_matrix</span></a>
<a href="../../modules/generated/nistats.reporting.plot_contrast_matrix.html#nistats.reporting.plot_contrast_matrix" title="View documentation for nistats.reporting.plot_contrast_matrix"><span class="n">plot_contrast_matrix</span></a><span class="p">(</span><span class="n">active_minus_rest</span><span class="p">,</span> <span class="n">design_matrix</span><span class="o">=</span><span class="n">design_matrix</span><span class="p">)</span>
</pre></div>
</div>
<img alt="../../_images/sphx_glr_plot_single_subject_single_run_005.png" class="sphx-glr-single-img" src="../../_images/sphx_glr_plot_single_subject_single_run_005.png" />
<p class="sphx-glr-script-out">Out:</p>
<div class="sphx-glr-script-out highlight-none notranslate"><div class="highlight"><pre><span></span>/home/kshitij/.programs/anaconda3/envs/nistats-py36-latest/lib/python3.6/site-packages/numpy/matrixlib/defmatrix.py:68: PendingDeprecationWarning: the matrix subclass is not the recommended way to represent matrices or deal with linear algebra (see https://docs.scipy.org/doc/numpy/user/numpy-for-matlab-users.html). Please adjust your code to use regular ndarray.
  return matrix(data, dtype=dtype, copy=False)
</pre></div>
</div>
<p>Below, we compute the estimated effect. It is in BOLD signal unit,
but has no statistical guarantees, because it does not take into
account the associated variance.</p>
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span><span class="n">eff_map</span> <span class="o">=</span> <span class="n">fmri_glm</span><span class="o">.</span><span class="n">compute_contrast</span><span class="p">(</span><span class="n">active_minus_rest</span><span class="p">,</span>
                                    <span class="n">output_type</span><span class="o">=</span><span class="s1">&#39;effect_size&#39;</span><span class="p">)</span>
</pre></div>
</div>
<p>In order to get statistical significance, we form a t-statistic, and
directly convert is into z-scale. The z-scale means that the values
are scaled to match a standard Gaussian distribution (mean=0,
variance=1), across voxels, if there were now effects in the data.</p>
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span><span class="n">z_map</span> <span class="o">=</span> <span class="n">fmri_glm</span><span class="o">.</span><span class="n">compute_contrast</span><span class="p">(</span><span class="n">active_minus_rest</span><span class="p">,</span>
                                  <span class="n">output_type</span><span class="o">=</span><span class="s1">&#39;z_score&#39;</span><span class="p">)</span>
</pre></div>
</div>
<p>Plot thresholded z scores map.</p>
<p>We display it on top of the average
functional image of the series (could be the anatomical image of the
subject).  We use arbitrarily a threshold of 3.0 in z-scale. We’ll
see later how to use corrected thresholds. We will show 3
axial views, with display_mode=’z’ and cut_coords=3</p>
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span><a href="http://nilearn.github.io/modules/generated/nilearn.plotting.plot_stat_map.html#nilearn.plotting.plot_stat_map" title="View documentation for nilearn.plotting.plot_stat_map"><span class="n">plot_stat_map</span></a><span class="p">(</span><span class="n">z_map</span><span class="p">,</span> <span class="n">bg_img</span><span class="o">=</span><a href="http://nilearn.github.io/modules/generated/nilearn.image.mean_img.html#nilearn.image.mean_img" title="View documentation for nilearn.image.mean_img"><span class="n">mean_img</span></a><span class="p">,</span> <span class="n">threshold</span><span class="o">=</span><span class="mf">3.0</span><span class="p">,</span>
              <span class="n">display_mode</span><span class="o">=</span><span class="s1">&#39;z&#39;</span><span class="p">,</span> <span class="n">cut_coords</span><span class="o">=</span><span class="mi">3</span><span class="p">,</span> <span class="n">black_bg</span><span class="o">=</span><span class="kc">True</span><span class="p">,</span>
              <span class="n">title</span><span class="o">=</span><span class="s1">&#39;Active minus Rest (Z&gt;3)&#39;</span><span class="p">)</span>
<a href="https://matplotlib.org/api/_as_gen/matplotlib.pyplot.show.html#matplotlib.pyplot.show" title="View documentation for matplotlib.pyplot.show"><span class="n">plt</span><span class="o">.</span><span class="n">show</span></a><span class="p">()</span>
</pre></div>
</div>
<img alt="../../_images/sphx_glr_plot_single_subject_single_run_006.png" class="sphx-glr-single-img" src="../../_images/sphx_glr_plot_single_subject_single_run_006.png" />
<p>Statistical significance testing. One should worry about the
statistical validity of the procedure: here we used an arbitrary
threshold of 3.0 but the threshold should provide some guarantees on
the risk of false detections (aka type-1 errors in statistics).
One suggestion is to control the false positive rate (fpr, denoted by
alpha) at a certain level, e.g. 0.001: this means that there is 0.1% chance
of declaring an inactive voxel, active.</p>
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span><span class="kn">from</span> <span class="nn">nistats.thresholding</span> <span class="k">import</span> <a href="../../modules/generated/nistats.thresholding.map_threshold.html#nistats.thresholding.map_threshold" title="View documentation for nistats.thresholding.map_threshold"><span class="n">map_threshold</span></a>
<span class="n">_</span><span class="p">,</span> <span class="n">threshold</span> <span class="o">=</span> <a href="../../modules/generated/nistats.thresholding.map_threshold.html#nistats.thresholding.map_threshold" title="View documentation for nistats.thresholding.map_threshold"><span class="n">map_threshold</span></a><span class="p">(</span><span class="n">z_map</span><span class="p">,</span> <span class="n">alpha</span><span class="o">=.</span><span class="mi">001</span><span class="p">,</span> <span class="n">height_control</span><span class="o">=</span><span class="s1">&#39;fpr&#39;</span><span class="p">)</span>
<span class="nb">print</span><span class="p">(</span><span class="s1">&#39;Uncorrected p&lt;0.001 threshold: </span><span class="si">%.3f</span><span class="s1">&#39;</span> <span class="o">%</span> <span class="n">threshold</span><span class="p">)</span>
<a href="http://nilearn.github.io/modules/generated/nilearn.plotting.plot_stat_map.html#nilearn.plotting.plot_stat_map" title="View documentation for nilearn.plotting.plot_stat_map"><span class="n">plot_stat_map</span></a><span class="p">(</span><span class="n">z_map</span><span class="p">,</span> <span class="n">bg_img</span><span class="o">=</span><a href="http://nilearn.github.io/modules/generated/nilearn.image.mean_img.html#nilearn.image.mean_img" title="View documentation for nilearn.image.mean_img"><span class="n">mean_img</span></a><span class="p">,</span> <span class="n">threshold</span><span class="o">=</span><span class="n">threshold</span><span class="p">,</span>
              <span class="n">display_mode</span><span class="o">=</span><span class="s1">&#39;z&#39;</span><span class="p">,</span> <span class="n">cut_coords</span><span class="o">=</span><span class="mi">3</span><span class="p">,</span> <span class="n">black_bg</span><span class="o">=</span><span class="kc">True</span><span class="p">,</span>
              <span class="n">title</span><span class="o">=</span><span class="s1">&#39;Active minus Rest (p&lt;0.001)&#39;</span><span class="p">)</span>
<a href="https://matplotlib.org/api/_as_gen/matplotlib.pyplot.show.html#matplotlib.pyplot.show" title="View documentation for matplotlib.pyplot.show"><span class="n">plt</span><span class="o">.</span><span class="n">show</span></a><span class="p">()</span>
</pre></div>
</div>
<img alt="../../_images/sphx_glr_plot_single_subject_single_run_007.png" class="sphx-glr-single-img" src="../../_images/sphx_glr_plot_single_subject_single_run_007.png" />
<p class="sphx-glr-script-out">Out:</p>
<div class="sphx-glr-script-out highlight-none notranslate"><div class="highlight"><pre><span></span>Uncorrected p&lt;0.001 threshold: 3.090
</pre></div>
</div>
<p>The problem is that with this you expect 0.001 * n_voxels to show up
while they’re not active — tens to hundreds of voxels. A more
conservative solution is to control the family wise error rate,
i.e. the probability of making only one false detection, say at
5%. For that we use the so-called Bonferroni correction</p>
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span><span class="n">_</span><span class="p">,</span> <span class="n">threshold</span> <span class="o">=</span> <a href="../../modules/generated/nistats.thresholding.map_threshold.html#nistats.thresholding.map_threshold" title="View documentation for nistats.thresholding.map_threshold"><span class="n">map_threshold</span></a><span class="p">(</span><span class="n">z_map</span><span class="p">,</span> <span class="n">alpha</span><span class="o">=.</span><span class="mi">05</span><span class="p">,</span> <span class="n">height_control</span><span class="o">=</span><span class="s1">&#39;bonferroni&#39;</span><span class="p">)</span>
<span class="nb">print</span><span class="p">(</span><span class="s1">&#39;Bonferroni-corrected, p&lt;0.05 threshold: </span><span class="si">%.3f</span><span class="s1">&#39;</span> <span class="o">%</span> <span class="n">threshold</span><span class="p">)</span>
<a href="http://nilearn.github.io/modules/generated/nilearn.plotting.plot_stat_map.html#nilearn.plotting.plot_stat_map" title="View documentation for nilearn.plotting.plot_stat_map"><span class="n">plot_stat_map</span></a><span class="p">(</span><span class="n">z_map</span><span class="p">,</span> <span class="n">bg_img</span><span class="o">=</span><a href="http://nilearn.github.io/modules/generated/nilearn.image.mean_img.html#nilearn.image.mean_img" title="View documentation for nilearn.image.mean_img"><span class="n">mean_img</span></a><span class="p">,</span> <span class="n">threshold</span><span class="o">=</span><span class="n">threshold</span><span class="p">,</span>
              <span class="n">display_mode</span><span class="o">=</span><span class="s1">&#39;z&#39;</span><span class="p">,</span> <span class="n">cut_coords</span><span class="o">=</span><span class="mi">3</span><span class="p">,</span> <span class="n">black_bg</span><span class="o">=</span><span class="kc">True</span><span class="p">,</span>
              <span class="n">title</span><span class="o">=</span><span class="s1">&#39;Active minus Rest (p&lt;0.05, corrected)&#39;</span><span class="p">)</span>
<a href="https://matplotlib.org/api/_as_gen/matplotlib.pyplot.show.html#matplotlib.pyplot.show" title="View documentation for matplotlib.pyplot.show"><span class="n">plt</span><span class="o">.</span><span class="n">show</span></a><span class="p">()</span>
</pre></div>
</div>
<img alt="../../_images/sphx_glr_plot_single_subject_single_run_008.png" class="sphx-glr-single-img" src="../../_images/sphx_glr_plot_single_subject_single_run_008.png" />
<p class="sphx-glr-script-out">Out:</p>
<div class="sphx-glr-script-out highlight-none notranslate"><div class="highlight"><pre><span></span>Bonferroni-corrected, p&lt;0.05 threshold: 4.797
</pre></div>
</div>
<p>This is quite conservative indeed!  A popular alternative is to
control the expected proportion of
false discoveries among detections. This is called the false
discovery rate</p>
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span><span class="n">_</span><span class="p">,</span> <span class="n">threshold</span> <span class="o">=</span> <a href="../../modules/generated/nistats.thresholding.map_threshold.html#nistats.thresholding.map_threshold" title="View documentation for nistats.thresholding.map_threshold"><span class="n">map_threshold</span></a><span class="p">(</span><span class="n">z_map</span><span class="p">,</span> <span class="n">alpha</span><span class="o">=.</span><span class="mi">05</span><span class="p">,</span> <span class="n">height_control</span><span class="o">=</span><span class="s1">&#39;fdr&#39;</span><span class="p">)</span>
<span class="nb">print</span><span class="p">(</span><span class="s1">&#39;False Discovery rate = 0.05 threshold: </span><span class="si">%.3f</span><span class="s1">&#39;</span> <span class="o">%</span> <span class="n">threshold</span><span class="p">)</span>
<a href="http://nilearn.github.io/modules/generated/nilearn.plotting.plot_stat_map.html#nilearn.plotting.plot_stat_map" title="View documentation for nilearn.plotting.plot_stat_map"><span class="n">plot_stat_map</span></a><span class="p">(</span><span class="n">z_map</span><span class="p">,</span> <span class="n">bg_img</span><span class="o">=</span><a href="http://nilearn.github.io/modules/generated/nilearn.image.mean_img.html#nilearn.image.mean_img" title="View documentation for nilearn.image.mean_img"><span class="n">mean_img</span></a><span class="p">,</span> <span class="n">threshold</span><span class="o">=</span><span class="n">threshold</span><span class="p">,</span>
              <span class="n">display_mode</span><span class="o">=</span><span class="s1">&#39;z&#39;</span><span class="p">,</span> <span class="n">cut_coords</span><span class="o">=</span><span class="mi">3</span><span class="p">,</span> <span class="n">black_bg</span><span class="o">=</span><span class="kc">True</span><span class="p">,</span>
              <span class="n">title</span><span class="o">=</span><span class="s1">&#39;Active minus Rest (fdr=0.05)&#39;</span><span class="p">)</span>
<a href="https://matplotlib.org/api/_as_gen/matplotlib.pyplot.show.html#matplotlib.pyplot.show" title="View documentation for matplotlib.pyplot.show"><span class="n">plt</span><span class="o">.</span><span class="n">show</span></a><span class="p">()</span>
</pre></div>
</div>
<img alt="../../_images/sphx_glr_plot_single_subject_single_run_009.png" class="sphx-glr-single-img" src="../../_images/sphx_glr_plot_single_subject_single_run_009.png" />
<p class="sphx-glr-script-out">Out:</p>
<div class="sphx-glr-script-out highlight-none notranslate"><div class="highlight"><pre><span></span>False Discovery rate = 0.05 threshold: 2.760
</pre></div>
</div>
<p>Finally people like to discard isolated voxels (aka “small
clusters”) from these images. It is possible to generate a
thresholded map with small clusters removed by providing a
cluster_threshold argument. Here clusters smaller than 10 voxels
will be discarded.</p>
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span><span class="n">clean_map</span><span class="p">,</span> <span class="n">threshold</span> <span class="o">=</span> <a href="../../modules/generated/nistats.thresholding.map_threshold.html#nistats.thresholding.map_threshold" title="View documentation for nistats.thresholding.map_threshold"><span class="n">map_threshold</span></a><span class="p">(</span>
    <span class="n">z_map</span><span class="p">,</span> <span class="n">alpha</span><span class="o">=.</span><span class="mi">05</span><span class="p">,</span> <span class="n">height_control</span><span class="o">=</span><span class="s1">&#39;fdr&#39;</span><span class="p">,</span> <span class="n">cluster_threshold</span><span class="o">=</span><span class="mi">10</span><span class="p">)</span>
<a href="http://nilearn.github.io/modules/generated/nilearn.plotting.plot_stat_map.html#nilearn.plotting.plot_stat_map" title="View documentation for nilearn.plotting.plot_stat_map"><span class="n">plot_stat_map</span></a><span class="p">(</span><span class="n">clean_map</span><span class="p">,</span> <span class="n">bg_img</span><span class="o">=</span><a href="http://nilearn.github.io/modules/generated/nilearn.image.mean_img.html#nilearn.image.mean_img" title="View documentation for nilearn.image.mean_img"><span class="n">mean_img</span></a><span class="p">,</span> <span class="n">threshold</span><span class="o">=</span><span class="n">threshold</span><span class="p">,</span>
              <span class="n">display_mode</span><span class="o">=</span><span class="s1">&#39;z&#39;</span><span class="p">,</span> <span class="n">cut_coords</span><span class="o">=</span><span class="mi">3</span><span class="p">,</span> <span class="n">black_bg</span><span class="o">=</span><span class="kc">True</span><span class="p">,</span>
              <span class="n">title</span><span class="o">=</span><span class="s1">&#39;Active minus Rest (fdr=0.05), clusters &gt; 10 voxels&#39;</span><span class="p">)</span>
<a href="https://matplotlib.org/api/_as_gen/matplotlib.pyplot.show.html#matplotlib.pyplot.show" title="View documentation for matplotlib.pyplot.show"><span class="n">plt</span><span class="o">.</span><span class="n">show</span></a><span class="p">()</span>
</pre></div>
</div>
<img alt="../../_images/sphx_glr_plot_single_subject_single_run_010.png" class="sphx-glr-single-img" src="../../_images/sphx_glr_plot_single_subject_single_run_010.png" />
<p>We can save the effect and zscore maps to the disk</p>
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span><span class="n">z_map</span><span class="o">.</span><span class="n">to_filename</span><span class="p">(</span><span class="n">join</span><span class="p">(</span><span class="n">outdir</span><span class="p">,</span> <span class="s1">&#39;active_vs_rest_z_map.nii.gz&#39;</span><span class="p">))</span>
<span class="n">eff_map</span><span class="o">.</span><span class="n">to_filename</span><span class="p">(</span><span class="n">join</span><span class="p">(</span><span class="n">outdir</span><span class="p">,</span> <span class="s1">&#39;active_vs_rest_eff_map.nii.gz&#39;</span><span class="p">))</span>
</pre></div>
</div>
<p>Report the found positions in a table</p>
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span><span class="kn">from</span> <span class="nn">nistats.reporting</span> <span class="k">import</span> <a href="../../modules/generated/nistats.reporting.get_clusters_table.html#nistats.reporting.get_clusters_table" title="View documentation for nistats.reporting.get_clusters_table"><span class="n">get_clusters_table</span></a>
<span class="n">table</span> <span class="o">=</span> <a href="../../modules/generated/nistats.reporting.get_clusters_table.html#nistats.reporting.get_clusters_table" title="View documentation for nistats.reporting.get_clusters_table"><span class="n">get_clusters_table</span></a><span class="p">(</span><span class="n">z_map</span><span class="p">,</span> <span class="n">stat_threshold</span><span class="o">=</span><span class="n">threshold</span><span class="p">,</span>
                           <span class="n">cluster_threshold</span><span class="o">=</span><span class="mi">20</span><span class="p">)</span>
<span class="nb">print</span><span class="p">(</span><span class="n">table</span><span class="p">)</span>
</pre></div>
</div>
<p class="sphx-glr-script-out">Out:</p>
<div class="sphx-glr-script-out highlight-none notranslate"><div class="highlight"><pre><span></span>   Cluster ID     X     Y     Z  Peak Stat Cluster Size (mm3)
0           1 -60.0  -6.0  42.0   9.811979               4590
1          1a -63.0   6.0  36.0   8.601922
2          1b -63.0   0.0  42.0   8.399054
3          1c -48.0 -15.0  39.0   8.364058
4           2  60.0   0.0  36.0   9.605127               1728
5          2a  45.0 -12.0  42.0   7.590201
6          2b  69.0   6.0  30.0   4.136199
7           3  63.0  12.0  27.0   8.284500                999
8          3a  51.0   3.0  30.0   6.968355
9          3b  54.0   9.0  39.0   3.565609
10          4  36.0  -3.0  15.0   8.087450               1269
11          5  51.0  30.0  27.0   7.850265                756
12         5a  48.0  21.0  27.0   7.411894
13         5b  57.0  39.0  27.0   6.043533
14         5c  45.0   9.0  27.0   5.133463
15          6 -63.0 -18.0  27.0   5.807508                810
16         6a -63.0 -21.0  42.0   5.646351
17         6b -60.0 -21.0  33.0   5.416272
18         6c -63.0  -9.0  24.0   4.292129
19          7  45.0 -18.0  57.0   5.710963               1053
20         7a  36.0 -12.0  57.0   5.633747
21         7b  30.0  -9.0  66.0   4.796135
22         7c  36.0 -15.0  69.0   4.254544
23          8 -12.0 -15.0  93.0   5.522476                621
24         8a  -6.0 -15.0  99.0   4.713854
25         8b  -3.0 -18.0  90.0   4.270732
26         8c -18.0 -12.0  96.0   4.085567
27          9  -3.0 -27.0  90.0   5.406320                891
28         9a -24.0 -24.0  90.0   5.331806
29         9b -36.0 -24.0  90.0   4.700089
30         9c -12.0 -24.0  81.0   4.193729
31         10 -15.0 -60.0  66.0   4.835098                918
32        10a -15.0 -60.0  57.0   4.615643
33        10b  -6.0 -63.0  63.0   4.091567
34         11 -12.0 -69.0  51.0   4.565542                540
35        11a -24.0 -63.0  51.0   3.855582
36        11b  -6.0 -69.0  51.0   3.784628
</pre></div>
</div>
<p>the table can be saved for future use</p>
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span><span class="n">table</span><span class="o">.</span><span class="n">to_csv</span><span class="p">(</span><span class="n">join</span><span class="p">(</span><span class="n">outdir</span><span class="p">,</span> <span class="s1">&#39;table.csv&#39;</span><span class="p">))</span>
</pre></div>
</div>
<p>Performing an F-test</p>
<p>“active vs rest” is a typical t test: condition versus
baseline. Another popular type of test is an F test in which one
seeks whether a certain combination of conditions (possibly two-,
three- or higher-dimensional) explains a significant proportion of
the signal.  Here one might for instance test which voxels are well
explained by combination of the active and rest condition.</p>
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span><span class="kn">import</span> <span class="nn">numpy</span> <span class="k">as</span> <span class="nn">np</span>
<span class="n">effects_of_interest</span> <span class="o">=</span> <a href="https://docs.scipy.org/doc/numpy/reference/generated/numpy.vstack.html#numpy.vstack" title="View documentation for numpy.vstack"><span class="n">np</span><span class="o">.</span><span class="n">vstack</span></a><span class="p">((</span><span class="n">conditions</span><span class="p">[</span><span class="s1">&#39;active&#39;</span><span class="p">],</span> <span class="n">conditions</span><span class="p">[</span><span class="s1">&#39;rest&#39;</span><span class="p">]))</span>
<a href="../../modules/generated/nistats.reporting.plot_contrast_matrix.html#nistats.reporting.plot_contrast_matrix" title="View documentation for nistats.reporting.plot_contrast_matrix"><span class="n">plot_contrast_matrix</span></a><span class="p">(</span><span class="n">effects_of_interest</span><span class="p">,</span> <span class="n">design_matrix</span><span class="p">)</span>
<a href="https://matplotlib.org/api/_as_gen/matplotlib.pyplot.show.html#matplotlib.pyplot.show" title="View documentation for matplotlib.pyplot.show"><span class="n">plt</span><span class="o">.</span><span class="n">show</span></a><span class="p">()</span>
</pre></div>
</div>
<img alt="../../_images/sphx_glr_plot_single_subject_single_run_011.png" class="sphx-glr-single-img" src="../../_images/sphx_glr_plot_single_subject_single_run_011.png" />
<p>Specify the contrast and compute the corresponding map. Actually, the
contrast specification is done exactly the same way as for t-
contrasts.</p>
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span><span class="n">z_map</span> <span class="o">=</span> <span class="n">fmri_glm</span><span class="o">.</span><span class="n">compute_contrast</span><span class="p">(</span><span class="n">effects_of_interest</span><span class="p">,</span>
                                  <span class="n">output_type</span><span class="o">=</span><span class="s1">&#39;z_score&#39;</span><span class="p">)</span>
<a href="https://matplotlib.org/api/_as_gen/matplotlib.pyplot.show.html#matplotlib.pyplot.show" title="View documentation for matplotlib.pyplot.show"><span class="n">plt</span><span class="o">.</span><span class="n">show</span></a><span class="p">()</span>
</pre></div>
</div>
<p>Note that the statistic has been converted to a z-variable, which
makes it easier to represent it.</p>
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span><span class="n">clean_map</span><span class="p">,</span> <span class="n">threshold</span> <span class="o">=</span> <a href="../../modules/generated/nistats.thresholding.map_threshold.html#nistats.thresholding.map_threshold" title="View documentation for nistats.thresholding.map_threshold"><span class="n">map_threshold</span></a><span class="p">(</span>
    <span class="n">z_map</span><span class="p">,</span> <span class="n">alpha</span><span class="o">=.</span><span class="mi">05</span><span class="p">,</span> <span class="n">height_control</span><span class="o">=</span><span class="s1">&#39;fdr&#39;</span><span class="p">,</span> <span class="n">cluster_threshold</span><span class="o">=</span><span class="mi">10</span><span class="p">)</span>
<a href="http://nilearn.github.io/modules/generated/nilearn.plotting.plot_stat_map.html#nilearn.plotting.plot_stat_map" title="View documentation for nilearn.plotting.plot_stat_map"><span class="n">plot_stat_map</span></a><span class="p">(</span><span class="n">clean_map</span><span class="p">,</span> <span class="n">bg_img</span><span class="o">=</span><a href="http://nilearn.github.io/modules/generated/nilearn.image.mean_img.html#nilearn.image.mean_img" title="View documentation for nilearn.image.mean_img"><span class="n">mean_img</span></a><span class="p">,</span> <span class="n">threshold</span><span class="o">=</span><span class="n">threshold</span><span class="p">,</span>
              <span class="n">display_mode</span><span class="o">=</span><span class="s1">&#39;z&#39;</span><span class="p">,</span> <span class="n">cut_coords</span><span class="o">=</span><span class="mi">3</span><span class="p">,</span> <span class="n">black_bg</span><span class="o">=</span><span class="kc">True</span><span class="p">,</span>
              <span class="n">title</span><span class="o">=</span><span class="s1">&#39;Effects of interest (fdr=0.05), clusters &gt; 10 voxels&#39;</span><span class="p">)</span>
<a href="https://matplotlib.org/api/_as_gen/matplotlib.pyplot.show.html#matplotlib.pyplot.show" title="View documentation for matplotlib.pyplot.show"><span class="n">plt</span><span class="o">.</span><span class="n">show</span></a><span class="p">()</span>
</pre></div>
</div>
<img alt="../../_images/sphx_glr_plot_single_subject_single_run_012.png" class="sphx-glr-single-img" src="../../_images/sphx_glr_plot_single_subject_single_run_012.png" />
<p>Oops, there is a lot of non-neural signal in there (ventricles, arteries)…</p>
<p class="sphx-glr-timing"><strong>Total running time of the script:</strong> ( 0 minutes  7.751 seconds)</p>
<div class="sphx-glr-footer class sphx-glr-footer-example docutils container" id="sphx-glr-download-auto-examples-01-tutorials-plot-single-subject-single-run-py">
<div class="sphx-glr-download docutils container">
<p><a class="reference download internal" download="" href="../../_downloads/dd7d5b88d94e168cce5fa0d8aab07ddf/plot_single_subject_single_run.py"><code class="xref download docutils literal notranslate"><span class="pre">Download</span> <span class="pre">Python</span> <span class="pre">source</span> <span class="pre">code:</span> <span class="pre">plot_single_subject_single_run.py</span></code></a></p>
</div>
<div class="sphx-glr-download docutils container">
<p><a class="reference download internal" download="" href="../../_downloads/4fa5cef1f5999b70587ddc842933cd35/plot_single_subject_single_run.ipynb"><code class="xref download docutils literal notranslate"><span class="pre">Download</span> <span class="pre">Jupyter</span> <span class="pre">notebook:</span> <span class="pre">plot_single_subject_single_run.ipynb</span></code></a></p>
</div>
</div>
<p class="sphx-glr-signature"><a class="reference external" href="https://sphinx-gallery.github.io">Gallery generated by Sphinx-Gallery</a></p>
</div>
</div>


          </div>
        </div>
      </div>
      <div class="clearer"></div>
    </div>
    <div class="related" role="navigation" aria-label="related navigation">
      <h3>Navigation</h3>
      <ul>
        <li class="right" style="margin-right: 10px">
          <a href="../../py-modindex.html" title="Python Module Index"
             >modules</a></li>
        <li class="right" >
          <a href="plot_first_level_model_details.html" title="2.1.2. Studying first-level-model details in a trials-and-error fashion"
             >next</a> |</li>
        <li class="right" >
          <a href="../index.html" title="2. Nistats usage examples"
             >previous</a> |</li>
<li><a href="../../index.html">Nistats Home</a> |&nbsp;</li>
<li><a href="../../user_guide.html">User Guide</a> |&nbsp;</li>
<li><a href="../index.html">Examples</a> |&nbsp;</li>
<li><a href="../../modules/reference.html">Reference</a> |&nbsp;</li>
<li id="navbar-about"><a href="../../authors.html">About</a>|&nbsp;</li>
<li id="navbar-ecosystem"><a href="http://www.nipy.org/">Nipy ecosystem</a></li>

          <li class="nav-item nav-item-1"><a href="../../user_guide.html" >User guide: table of contents</a> &#187;</li>
          <li class="nav-item nav-item-2"><a href="../index.html" >2. Nistats usage examples</a> &#187;</li> 
      </ul>
    </div>
    <div class="footer">
            &copy; The nistats developers 2010-2016.
          Created using <a href="http://sphinx.pocoo.org/">Sphinx</a> 2.1.2.
        <span style="padding-left: 5ex;">
          <a href="../../_sources/auto_examples/01_tutorials/plot_single_subject_single_run.rst.txt"
        	 rel="nofollow">Show this page source</a>
        </span>
    </div>
  </body>
</html>