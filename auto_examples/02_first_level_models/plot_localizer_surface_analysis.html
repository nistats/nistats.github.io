
<!DOCTYPE html>

<html xmlns="http://www.w3.org/1999/xhtml" lang="en">
  <head>
    <meta http-equiv="X-UA-Compatible" content="IE=Edge" />
    <meta http-equiv="Content-Type" content="text/html; charset=utf-8" />
    <title>Nistats: Functional MRI in Python &#8212; functional MRI for NeuroImaging</title>
    <link rel="stylesheet" href="../../_static/nature.css" type="text/css" />
    <link rel="stylesheet" href="../../_static/pygments.css" type="text/css" />
    <link rel="stylesheet" href="../../_static/gallery.css" type="text/css" />
    <script type="text/javascript" id="documentation_options" data-url_root="../../" src="../../_static/documentation_options.js"></script>
    <script type="text/javascript" src="../../_static/jquery.js"></script>
    <script type="text/javascript" src="../../_static/underscore.js"></script>
    <script type="text/javascript" src="../../_static/doctools.js"></script>
    <script type="text/javascript" src="../../_static/copybutton.js"></script>
    <link rel="shortcut icon" href="../../_static/favicon.ico"/>
    <link rel="search" title="Search" href="../../search.html" />
    <link rel="next" title="2.3.1. Example of generic design in second-level models" href="../03_second_level_models/plot_second_level_association_test.html" />
    <link rel="prev" title="2.2.4. First level analysis of a complete BIDS dataset from openneuro" href="plot_bids_features.html" />
<meta content="True" name="HandheldFriendly">
<meta name="viewport" content="width=device-width, initial-scale=1.0, maximum-scale=1.0, user-scalable=0">
<meta name="keywords" content="nistats, neuroimaging, python, neuroscience, statistics">
<script type="text/javascript">
$(function () {
    // Lock the table of content to a fixed position once we scroll enough
    var top = 105 + $('.sphinxsidebarwrapper').offset().top - parseFloat($('.sphinxsidebarwrapper').css('margin-top').replace(/auto/, 0)),
        sections = {},
        i        = 0,
	url	 = document.URL.replace(/#.*$/, ""),
	current_section = 0;

    // Grab positions of our sections
    $('.headerlink').each(function(){
        sections[this.href.replace(url, '')] = $(this).offset().top - 50;
    });

    $(window).scroll(function(event) {
	var pos   = $(window).scrollTop();
	// Lock the table of content to a fixed position once we scroll enough
	if(pos > top){
	    //begin to scroll
	    $('.sphinxsidebarwrapper').css("position", "fixed");
	    $('.sphinxsidebarwrapper').css("top", -105);
	}
	else{
	    //lock it back into place
	    $('.sphinxsidebarwrapper').css("position", "relative");
	    $('.sphinxsidebarwrapper').css("top",0);
	}

	// Highlight the current section
	$('a.internal').removeClass('active');
        for(i in sections){
            if(sections[i] > pos){
		break;
            };
	    if($('a.internal[href$="' + i + '"]').is(':visible')){
		current_section = i;
	    };
        }
	$('a.internal[href$="' + current_section + '"]').addClass('active');
    });

});
</script>


<script type="text/javascript">

        var _gaq = _gaq || [];
        _gaq.push(['_setAccount', 'UA-41920728-1']);
        _gaq.push(['_trackPageview']);

        (function() {
            var ga = document.createElement('script'); ga.type = 'text/javascript'; ga.async = true;
            ga.src = ('https:' == document.location.protocol ? 'https://ssl' : 'http://www') + '.google-analytics.com/ga.js';
            var s = document.getElementsByTagName('script')[0]; s.parentNode.insertBefore(ga, s);
        })();
    </script>

  </head><body>
<div id="logo-banner">
  <div class="logo">
    <a href="../../index.html">
      <img src="../../_static/nistats-logo.png" alt="Nistats logo"  border="0" />
    </a>
  </div>
  <!-- A tag cloud to make it easy for people to find what they are
                         looking for -->
 <div class="tags">
  <ul>
    <li>
      <big><a href="../04_low_level_functions/plot_hrf.html">HRF</a></big>
    </li>
    <li>
      <small><a href="../04_low_level_functions/plot_design_matrix.html">Design Matrix</a></small>
    </li>
    <li>
      <small><a href="plot_localizer_analysis.html">First Level</a></small>
    </li>
    <li>
      <big><a href="../03_second_level_models/plot_thresholding.html">Second Level</a></big>
    </li>
    <li>
      <big><a href="../01_tutorials/plot_bids_analysis.html">BIDS datasets</a></big>
    </li>
  </ul>
 </div>

  <div class="banner">
    <h1>Nistats:</h1>
    <h2>Functional MRI Neuro-Imaging in Python</h2>
  </div>
  <div class="search_form">
    <div id="cse" style="width: 100%;"></div>
    <script src="http://www.google.com/jsapi" type="text/javascript"></script>
    <script type="text/javascript">
      google.load('search', '1', {language : 'en'});
      google.setOnLoadCallback(function() {
      var customSearchControl = new google.search.CustomSearchControl('014136483057745874622:r-npolb1uki');
      customSearchControl.setResultSetSize(google.search.Search.FILTERED_CSE_RESULTSET);
      var options = new google.search.DrawOptions();
      options.setAutoComplete(true);
      customSearchControl.draw('cse', options);
      }, true);
    </script>
  </div>
</div>



    <div class="related" role="navigation" aria-label="related navigation">
      <h3>Navigation</h3>
      <ul>
        <li class="right" style="margin-right: 10px">
          <a href="../../py-modindex.html" title="Python Module Index"
             >modules</a></li>
        <li class="right" >
          <a href="../03_second_level_models/plot_second_level_association_test.html" title="2.3.1. Example of generic design in second-level models"
             accesskey="N">next</a> |</li>
        <li class="right" >
          <a href="plot_bids_features.html" title="2.2.4. First level analysis of a complete BIDS dataset from openneuro"
             accesskey="P">previous</a> |</li>
<li><a href="../../index.html">Nistats Home</a> |&nbsp;</li>
<li><a href="../../user_guide.html">User Guide</a> |&nbsp;</li>
<li><a href="../index.html">Examples</a> |&nbsp;</li>
<li><a href="../../modules/reference.html">Reference</a> |&nbsp;</li>
<li id="navbar-about"><a href="../../authors.html">About</a>|&nbsp;</li>
<li id="navbar-ecosystem"><a href="http://www.nipy.org/">Nipy ecosystem</a></li>

          <li class="nav-item nav-item-1"><a href="../../user_guide.html" >User guide: table of contents</a> &#187;</li>
          <li class="nav-item nav-item-2"><a href="../index.html" accesskey="U">2. Nistats usage examples</a> &#187;</li> 
      </ul>
    </div>
      <div class="sphinxsidebar" role="navigation" aria-label="main navigation">
        <div class="sphinxsidebarwrapper">


<h4> Giving credit </h4>
  <ul class="simple">
    <li><p>Please consider <a href="../../authors.html#citing">citing the
                    papers</a>.</p></li>
  </ul>

  <h3><a href="../../index.html">Table Of Contents</a></h3>
  <ul>
<li><a class="reference internal" href="#">2.2.5. Example of surface-based first-level analysis</a><ul>
<li><a class="reference internal" href="#prepare-data-and-analysis-parameters">2.2.5.1. Prepare data and analysis parameters</a></li>
<li><a class="reference internal" href="#project-the-fmri-image-to-the-surface">2.2.5.2. Project the fMRI image to the surface</a></li>
<li><a class="reference internal" href="#perform-first-level-analysis">2.2.5.3. Perform first level analysis</a></li>
<li><a class="reference internal" href="#estimate-contrasts">2.2.5.4. Estimate contrasts</a></li>
<li><a class="reference internal" href="#analysing-the-left-hemisphere">2.2.5.5. Analysing the left hemisphere</a></li>
</ul>
</li>
</ul>

  <h4>Previous topic</h4>
  <p class="topless"><a href="plot_bids_features.html"
                        title="previous chapter">2.2.4. First level analysis of a complete BIDS dataset from openneuro</a></p>
  <h4>Next topic</h4>
  <p class="topless"><a href="../03_second_level_models/plot_second_level_association_test.html"
                        title="next chapter">2.3.1. Example of generic design in second-level models</a></p>
<div id="searchbox" style="display: none" role="search">
  <h3>Quick search</h3>
    <div class="searchformwrapper">
    <form class="search" action="../../search.html" method="get">
      <input type="text" name="q" />
      <input type="submit" value="Go" />
      <input type="hidden" name="check_keywords" value="yes" />
      <input type="hidden" name="area" value="default" />
    </form>
    </div>
</div>
<script type="text/javascript">$('#searchbox').show(0);</script>
        </div>
      </div>

    <div class="document">
      <div class="documentwrapper">
        <div class="bodywrapper">
          <div class="body" role="main">
            
  <div class="section" id="example-of-surface-based-first-level-analysis">
<span id="sphx-glr-auto-examples-02-first-level-models-plot-localizer-surface-analysis-py"></span><h1>2.2.5. Example of surface-based first-level analysis<a class="headerlink" href="#example-of-surface-based-first-level-analysis" title="Permalink to this headline">Â¶</a></h1>
<p>Full step-by-step example of fitting a GLM to experimental data
sampled on the cortical surface and visualizing the results.</p>
<p>More specifically:</p>
<ol class="arabic simple">
<li>A sequence of fMRI volumes are loaded</li>
</ol>
<p>2. fMRI data are projected onto a reference cortical surface (the
freesurfer template, fsaverage)
3. A design matrix describing all the effects related to the data is computed
4. A GLM is applied to the dataset (effect/covariance,</p>
<blockquote>
<div>then contrast estimation)</div></blockquote>
<p>The result of the analysis are statistical maps that are defined on
the brain mesh. We display them using Nilearn capabilities.</p>
<p>The projection of fMRI data onto a given brain mesh requires that both
are initially defined in the same space.</p>
<ul class="simple">
<li>The functional data should be coregistered to the anatomy from which
the mesh was obtained.</li>
<li>Another possibility, used here, is to project the normalized fMRI
data to an MNI-coregistered mesh, such as fsaverage.</li>
</ul>
<p>The advantage of this second approach is that it makes it easy to run
second-level analyses on the surface. On the other hand, it is
obviously less accurate than using a subject-tailored mesh.</p>
<div class="section" id="prepare-data-and-analysis-parameters">
<h2>2.2.5.1. Prepare data and analysis parameters<a class="headerlink" href="#prepare-data-and-analysis-parameters" title="Permalink to this headline">Â¶</a></h2>
<p>Prepare timing parameters</p>
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="n">t_r</span> <span class="o">=</span> <span class="mf">2.4</span>
<span class="n">slice_time_ref</span> <span class="o">=</span> <span class="mf">0.5</span>
</pre></div>
</div>
<p>Prepare data
First the volume-based fMRI data.</p>
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="kn">from</span> <span class="nn">nistats.datasets</span> <span class="kn">import</span> <span class="n">fetch_localizer_first_level</span>
<span class="n">data</span> <span class="o">=</span> <span class="n">fetch_localizer_first_level</span><span class="p">()</span>
<span class="n">fmri_img</span> <span class="o">=</span> <span class="n">data</span><span class="o">.</span><span class="n">epi_img</span>
</pre></div>
</div>
<p>Second the experimental paradigm.</p>
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="n">events_file</span> <span class="o">=</span> <span class="n">data</span><span class="p">[</span><span class="s1">&#39;events&#39;</span><span class="p">]</span>
<span class="kn">import</span> <span class="nn">pandas</span> <span class="kn">as</span> <span class="nn">pd</span>
<span class="n">events</span> <span class="o">=</span> <a href="http://pandas.pydata.org/pandas-docs/stable/generated/pandas.read_table.html#pandas.read_table" title="View documentation for pandas.read_table"><span class="n">pd</span><span class="o">.</span><span class="n">read_table</span></a><span class="p">(</span><span class="n">events_file</span><span class="p">)</span>
</pre></div>
</div>
</div>
<div class="section" id="project-the-fmri-image-to-the-surface">
<h2>2.2.5.2. Project the fMRI image to the surface<a class="headerlink" href="#project-the-fmri-image-to-the-surface" title="Permalink to this headline">Â¶</a></h2>
<p>For this we need to get a mesh representing the geometry of the
surface.  we could use an individual mesh, but we first resort to a
standard mesh, the so-called fsaverage5 template from the Freesurfer
software.</p>
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="kn">import</span> <span class="nn">nilearn</span>
<span class="n">fsaverage</span> <span class="o">=</span> <span class="n">nilearn</span><span class="o">.</span><span class="n">datasets</span><span class="o">.</span><span class="n">fetch_surf_fsaverage5</span><span class="p">()</span>
</pre></div>
</div>
<p>The projection function simply takes the fMRI data and the mesh.
Note that those correspond spatially, are they are bothin MNI space.</p>
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="kn">from</span> <span class="nn">nilearn</span> <span class="kn">import</span> <span class="n">surface</span>
<span class="n">texture</span> <span class="o">=</span> <a href="http://nilearn.github.io/modules/generated/nilearn.surface.vol_to_surf.html#nilearn.surface.vol_to_surf" title="View documentation for nilearn.surface.vol_to_surf"><span class="n">surface</span><span class="o">.</span><span class="n">vol_to_surf</span></a><span class="p">(</span><span class="n">fmri_img</span><span class="p">,</span> <span class="n">fsaverage</span><span class="o">.</span><span class="n">pial_right</span><span class="p">)</span>
</pre></div>
</div>
</div>
<div class="section" id="perform-first-level-analysis">
<h2>2.2.5.3. Perform first level analysis<a class="headerlink" href="#perform-first-level-analysis" title="Permalink to this headline">Â¶</a></h2>
<p>This involves computing the design matrix and fitting the model.
We start by specifying the timing of fMRI frames</p>
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="kn">import</span> <span class="nn">numpy</span> <span class="kn">as</span> <span class="nn">np</span>
<span class="n">n_scans</span> <span class="o">=</span> <span class="n">texture</span><span class="o">.</span><span class="n">shape</span><span class="p">[</span><span class="mi">1</span><span class="p">]</span>
<span class="n">frame_times</span> <span class="o">=</span> <span class="n">t_r</span> <span class="o">*</span> <span class="p">(</span><a href="http://docs.scipy.org/doc/numpy-1.11.0/reference/generated/numpy.arange.html#numpy.arange" title="View documentation for numpy.arange"><span class="n">np</span><span class="o">.</span><span class="n">arange</span></a><span class="p">(</span><span class="n">n_scans</span><span class="p">)</span> <span class="o">+</span> <span class="o">.</span><span class="mi">5</span><span class="p">)</span>
</pre></div>
</div>
<p>Create the design matrix</p>
<p>We specify an hrf model containing Glover model and its time derivative
the drift model is implicitly a cosine basis with period cutoff 128s.</p>
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="kn">from</span> <span class="nn">nistats.design_matrix</span> <span class="kn">import</span> <span class="n">make_first_level_design_matrix</span>
<span class="n">design_matrix</span> <span class="o">=</span> <span class="n">make_first_level_design_matrix</span><span class="p">(</span><span class="n">frame_times</span><span class="p">,</span>
                                               <span class="n">events</span><span class="o">=</span><span class="n">events</span><span class="p">,</span>
                                               <span class="n">hrf_model</span><span class="o">=</span><span class="s1">&#39;glover + derivative&#39;</span>
                                               <span class="p">)</span>
</pre></div>
</div>
<p>Setup and fit GLM.
Note that the output consists in 2 variables: <cite>labels</cite> and <cite>fit</cite>
<cite>labels</cite> tags voxels according to noise autocorrelation.
<cite>estimates</cite> contains the parameter estimates.
We keep them for later contrast computation.</p>
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="kn">from</span> <span class="nn">nistats.first_level_model</span> <span class="kn">import</span> <span class="n">run_glm</span>
<span class="n">labels</span><span class="p">,</span> <span class="n">estimates</span> <span class="o">=</span> <span class="n">run_glm</span><span class="p">(</span><span class="n">texture</span><span class="o">.</span><span class="n">T</span><span class="p">,</span> <span class="n">design_matrix</span><span class="o">.</span><span class="n">values</span><span class="p">)</span>
</pre></div>
</div>
</div>
<div class="section" id="estimate-contrasts">
<h2>2.2.5.4. Estimate contrasts<a class="headerlink" href="#estimate-contrasts" title="Permalink to this headline">Â¶</a></h2>
<p>Specify the contrasts
For practical purpose, we first generate an identity matrix whose size is
the number of columns of the design matrix</p>
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="n">contrast_matrix</span> <span class="o">=</span> <a href="http://docs.scipy.org/doc/numpy-1.11.0/reference/generated/numpy.eye.html#numpy.eye" title="View documentation for numpy.eye"><span class="n">np</span><span class="o">.</span><span class="n">eye</span></a><span class="p">(</span><span class="n">design_matrix</span><span class="o">.</span><span class="n">shape</span><span class="p">[</span><span class="mi">1</span><span class="p">])</span>
</pre></div>
</div>
<p>first create basic contrasts</p>
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="n">basic_contrasts</span> <span class="o">=</span> <span class="nb">dict</span><span class="p">([(</span><span class="n">column</span><span class="p">,</span> <span class="n">contrast_matrix</span><span class="p">[</span><span class="n">i</span><span class="p">])</span>
                        <span class="k">for</span> <span class="n">i</span><span class="p">,</span> <span class="n">column</span> <span class="ow">in</span> <span class="nb">enumerate</span><span class="p">(</span><span class="n">design_matrix</span><span class="o">.</span><span class="n">columns</span><span class="p">)])</span>
</pre></div>
</div>
<p>add some intermediate contrasts</p>
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="n">basic_contrasts</span><span class="p">[</span><span class="s2">&quot;audio&quot;</span><span class="p">]</span> <span class="o">=</span> <span class="p">(</span><span class="n">basic_contrasts</span><span class="p">[</span><span class="s2">&quot;clicDaudio&quot;</span><span class="p">]</span>
                            <span class="o">+</span> <span class="n">basic_contrasts</span><span class="p">[</span><span class="s2">&quot;clicGaudio&quot;</span><span class="p">]</span>
                            <span class="o">+</span> <span class="n">basic_contrasts</span><span class="p">[</span><span class="s2">&quot;calculaudio&quot;</span><span class="p">]</span>
                            <span class="o">+</span> <span class="n">basic_contrasts</span><span class="p">[</span><span class="s2">&quot;phraseaudio&quot;</span><span class="p">]</span>
                            <span class="p">)</span>
<span class="n">basic_contrasts</span><span class="p">[</span><span class="s2">&quot;video&quot;</span><span class="p">]</span> <span class="o">=</span> <span class="p">(</span><span class="n">basic_contrasts</span><span class="p">[</span><span class="s2">&quot;clicDvideo&quot;</span><span class="p">]</span>
                            <span class="o">+</span> <span class="n">basic_contrasts</span><span class="p">[</span><span class="s2">&quot;clicGvideo&quot;</span><span class="p">]</span>
                            <span class="o">+</span> <span class="n">basic_contrasts</span><span class="p">[</span><span class="s2">&quot;calculvideo&quot;</span><span class="p">]</span>
                            <span class="o">+</span> <span class="n">basic_contrasts</span><span class="p">[</span><span class="s2">&quot;phrasevideo&quot;</span><span class="p">]</span>
                            <span class="p">)</span>
<span class="n">basic_contrasts</span><span class="p">[</span><span class="s2">&quot;computation&quot;</span><span class="p">]</span> <span class="o">=</span> <span class="p">(</span><span class="n">basic_contrasts</span><span class="p">[</span><span class="s2">&quot;calculaudio&quot;</span><span class="p">]</span>
                                  <span class="o">+</span> <span class="n">basic_contrasts</span><span class="p">[</span><span class="s2">&quot;calculvideo&quot;</span><span class="p">]</span>
                                  <span class="p">)</span>
<span class="n">basic_contrasts</span><span class="p">[</span><span class="s2">&quot;sentences&quot;</span><span class="p">]</span> <span class="o">=</span> <span class="p">(</span><span class="n">basic_contrasts</span><span class="p">[</span><span class="s2">&quot;phraseaudio&quot;</span><span class="p">]</span>
                                <span class="o">+</span> <span class="n">basic_contrasts</span><span class="p">[</span><span class="s2">&quot;phrasevideo&quot;</span><span class="p">]</span>
                                <span class="p">)</span>
</pre></div>
</div>
<p>Finally make a dictionary of more relevant contrasts</p>
<ul class="simple">
<li>âleft - right button pressâ probes motor activity in left versus right button presses</li>
<li>âaudio - videoâ probes the difference of activity between listening to some content or reading the same type of content (instructions, stories)</li>
<li>âcomputation - sentencesâ looks at the activity when performing a mental comptation task  versus simply reading sentences.</li>
</ul>
<p>Of course, we could define other contrasts, but we keep only 3 for simplicity.</p>
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="n">contrasts</span> <span class="o">=</span> <span class="p">{</span>
    <span class="s2">&quot;left - right button press&quot;</span><span class="p">:</span> <span class="p">(</span><span class="n">basic_contrasts</span><span class="p">[</span><span class="s2">&quot;clicGaudio&quot;</span><span class="p">]</span>
                                  <span class="o">+</span> <span class="n">basic_contrasts</span><span class="p">[</span><span class="s2">&quot;clicGvideo&quot;</span><span class="p">]</span>
                                  <span class="o">-</span> <span class="n">basic_contrasts</span><span class="p">[</span><span class="s2">&quot;clicDaudio&quot;</span><span class="p">]</span>
                                  <span class="o">-</span> <span class="n">basic_contrasts</span><span class="p">[</span><span class="s2">&quot;clicDvideo&quot;</span><span class="p">]</span>
                                  <span class="p">),</span>
    <span class="s2">&quot;audio - video&quot;</span><span class="p">:</span> <span class="n">basic_contrasts</span><span class="p">[</span><span class="s2">&quot;audio&quot;</span><span class="p">]</span> <span class="o">-</span> <span class="n">basic_contrasts</span><span class="p">[</span><span class="s2">&quot;video&quot;</span><span class="p">],</span>
    <span class="s2">&quot;computation - sentences&quot;</span><span class="p">:</span> <span class="p">(</span><span class="n">basic_contrasts</span><span class="p">[</span><span class="s2">&quot;computation&quot;</span><span class="p">]</span> <span class="o">-</span>
                                <span class="n">basic_contrasts</span><span class="p">[</span><span class="s2">&quot;sentences&quot;</span><span class="p">]</span>
                                <span class="p">)</span>
    <span class="p">}</span>
</pre></div>
</div>
<p>contrast estimation</p>
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="kn">from</span> <span class="nn">nistats.contrasts</span> <span class="kn">import</span> <span class="n">compute_contrast</span>
<span class="kn">from</span> <span class="nn">nilearn</span> <span class="kn">import</span> <span class="n">plotting</span>
</pre></div>
</div>
<p>iterate over contrasts</p>
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="k">for</span> <span class="n">index</span><span class="p">,</span> <span class="p">(</span><span class="n">contrast_id</span><span class="p">,</span> <span class="n">contrast_val</span><span class="p">)</span> <span class="ow">in</span> <span class="nb">enumerate</span><span class="p">(</span><span class="n">contrasts</span><span class="o">.</span><span class="n">items</span><span class="p">()):</span>
    <span class="k">print</span><span class="p">(</span><span class="s1">&#39;  Contrast </span><span class="si">% i</span><span class="s1"> out of </span><span class="si">%i</span><span class="s1">: </span><span class="si">%s</span><span class="s1">, right hemisphere&#39;</span> <span class="o">%</span>
          <span class="p">(</span><span class="n">index</span> <span class="o">+</span> <span class="mi">1</span><span class="p">,</span> <span class="nb">len</span><span class="p">(</span><span class="n">contrasts</span><span class="p">),</span> <span class="n">contrast_id</span><span class="p">))</span>
    <span class="c1"># compute contrast-related statistics</span>
    <span class="n">contrast</span> <span class="o">=</span> <span class="n">compute_contrast</span><span class="p">(</span><span class="n">labels</span><span class="p">,</span> <span class="n">estimates</span><span class="p">,</span> <span class="n">contrast_val</span><span class="p">,</span>
                                <span class="n">contrast_type</span><span class="o">=</span><span class="s1">&#39;t&#39;</span><span class="p">)</span>
    <span class="c1"># we present the Z-transform of the t map</span>
    <span class="n">z_score</span> <span class="o">=</span> <span class="n">contrast</span><span class="o">.</span><span class="n">z_score</span><span class="p">()</span>
    <span class="c1"># we plot it on the surface, on the inflated fsaverage mesh,</span>
    <span class="c1"># together with a suitable background to give an impression</span>
    <span class="c1"># of the cortex folding.</span>
    <a href="http://nilearn.github.io/modules/generated/nilearn.plotting.plot_surf_stat_map.html#nilearn.plotting.plot_surf_stat_map" title="View documentation for nilearn.plotting.plot_surf_stat_map"><span class="n">plotting</span><span class="o">.</span><span class="n">plot_surf_stat_map</span></a><span class="p">(</span>
        <span class="n">fsaverage</span><span class="o">.</span><span class="n">infl_right</span><span class="p">,</span> <span class="n">z_score</span><span class="p">,</span> <span class="n">hemi</span><span class="o">=</span><span class="s1">&#39;right&#39;</span><span class="p">,</span>
        <span class="n">title</span><span class="o">=</span><span class="n">contrast_id</span><span class="p">,</span> <span class="n">colorbar</span><span class="o">=</span><span class="bp">True</span><span class="p">,</span>
        <span class="n">threshold</span><span class="o">=</span><span class="mf">3.</span><span class="p">,</span> <span class="n">bg_map</span><span class="o">=</span><span class="n">fsaverage</span><span class="o">.</span><span class="n">sulc_right</span><span class="p">)</span>
</pre></div>
</div>
<ul class="sphx-glr-horizontal">
<li><a class="first reference internal image-reference" href="../../_images/sphx_glr_plot_localizer_surface_analysis_001.png"><img alt="../../_images/sphx_glr_plot_localizer_surface_analysis_001.png" src="../../_images/sphx_glr_plot_localizer_surface_analysis_001.png" style="width: 376.0px; height: 282.0px;" /></a>
</li>
<li><a class="first reference internal image-reference" href="../../_images/sphx_glr_plot_localizer_surface_analysis_002.png"><img alt="../../_images/sphx_glr_plot_localizer_surface_analysis_002.png" src="../../_images/sphx_glr_plot_localizer_surface_analysis_002.png" style="width: 376.0px; height: 282.0px;" /></a>
</li>
<li><a class="first reference internal image-reference" href="../../_images/sphx_glr_plot_localizer_surface_analysis_003.png"><img alt="../../_images/sphx_glr_plot_localizer_surface_analysis_003.png" src="../../_images/sphx_glr_plot_localizer_surface_analysis_003.png" style="width: 376.0px; height: 282.0px;" /></a>
</li>
</ul>
<p class="sphx-glr-script-out">Out:</p>
<div class="sphx-glr-script-out highlight-default notranslate"><div class="highlight"><pre><span></span><span class="n">Contrast</span>  <span class="mi">1</span> <span class="n">out</span> <span class="n">of</span> <span class="mi">3</span><span class="p">:</span> <span class="n">left</span> <span class="o">-</span> <span class="n">right</span> <span class="n">button</span> <span class="n">press</span><span class="p">,</span> <span class="n">right</span> <span class="n">hemisphere</span>
  <span class="n">Contrast</span>  <span class="mi">2</span> <span class="n">out</span> <span class="n">of</span> <span class="mi">3</span><span class="p">:</span> <span class="n">audio</span> <span class="o">-</span> <span class="n">video</span><span class="p">,</span> <span class="n">right</span> <span class="n">hemisphere</span>
  <span class="n">Contrast</span>  <span class="mi">3</span> <span class="n">out</span> <span class="n">of</span> <span class="mi">3</span><span class="p">:</span> <span class="n">computation</span> <span class="o">-</span> <span class="n">sentences</span><span class="p">,</span> <span class="n">right</span> <span class="n">hemisphere</span>
</pre></div>
</div>
</div>
<div class="section" id="analysing-the-left-hemisphere">
<h2>2.2.5.5. Analysing the left hemisphere<a class="headerlink" href="#analysing-the-left-hemisphere" title="Permalink to this headline">Â¶</a></h2>
<p>Note that it requires little additional code!</p>
<p>Project the fMRI data to the mesh</p>
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="n">texture</span> <span class="o">=</span> <a href="http://nilearn.github.io/modules/generated/nilearn.surface.vol_to_surf.html#nilearn.surface.vol_to_surf" title="View documentation for nilearn.surface.vol_to_surf"><span class="n">surface</span><span class="o">.</span><span class="n">vol_to_surf</span></a><span class="p">(</span><span class="n">fmri_img</span><span class="p">,</span> <span class="n">fsaverage</span><span class="o">.</span><span class="n">pial_left</span><span class="p">)</span>
</pre></div>
</div>
<p>Estimate the General Linear Model</p>
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="n">labels</span><span class="p">,</span> <span class="n">estimates</span> <span class="o">=</span> <span class="n">run_glm</span><span class="p">(</span><span class="n">texture</span><span class="o">.</span><span class="n">T</span><span class="p">,</span> <span class="n">design_matrix</span><span class="o">.</span><span class="n">values</span><span class="p">)</span>
</pre></div>
</div>
<p>Create contrast-specific maps</p>
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="k">for</span> <span class="n">index</span><span class="p">,</span> <span class="p">(</span><span class="n">contrast_id</span><span class="p">,</span> <span class="n">contrast_val</span><span class="p">)</span> <span class="ow">in</span> <span class="nb">enumerate</span><span class="p">(</span><span class="n">contrasts</span><span class="o">.</span><span class="n">items</span><span class="p">()):</span>
    <span class="k">print</span><span class="p">(</span><span class="s1">&#39;  Contrast </span><span class="si">% i</span><span class="s1"> out of </span><span class="si">%i</span><span class="s1">: </span><span class="si">%s</span><span class="s1">, left hemisphere&#39;</span> <span class="o">%</span>
          <span class="p">(</span><span class="n">index</span> <span class="o">+</span> <span class="mi">1</span><span class="p">,</span> <span class="nb">len</span><span class="p">(</span><span class="n">contrasts</span><span class="p">),</span> <span class="n">contrast_id</span><span class="p">))</span>
    <span class="c1"># compute contrasts</span>
    <span class="n">contrast</span> <span class="o">=</span> <span class="n">compute_contrast</span><span class="p">(</span><span class="n">labels</span><span class="p">,</span> <span class="n">estimates</span><span class="p">,</span> <span class="n">contrast_val</span><span class="p">,</span>
                                <span class="n">contrast_type</span><span class="o">=</span><span class="s1">&#39;t&#39;</span><span class="p">)</span>
    <span class="n">z_score</span> <span class="o">=</span> <span class="n">contrast</span><span class="o">.</span><span class="n">z_score</span><span class="p">()</span>
    <span class="c1"># Plot the result</span>
    <a href="http://nilearn.github.io/modules/generated/nilearn.plotting.plot_surf_stat_map.html#nilearn.plotting.plot_surf_stat_map" title="View documentation for nilearn.plotting.plot_surf_stat_map"><span class="n">plotting</span><span class="o">.</span><span class="n">plot_surf_stat_map</span></a><span class="p">(</span>
        <span class="n">fsaverage</span><span class="o">.</span><span class="n">infl_left</span><span class="p">,</span> <span class="n">z_score</span><span class="p">,</span> <span class="n">hemi</span><span class="o">=</span><span class="s1">&#39;left&#39;</span><span class="p">,</span>
        <span class="n">title</span><span class="o">=</span><span class="n">contrast_id</span><span class="p">,</span> <span class="n">colorbar</span><span class="o">=</span><span class="bp">True</span><span class="p">,</span>
        <span class="n">threshold</span><span class="o">=</span><span class="mf">3.</span><span class="p">,</span> <span class="n">bg_map</span><span class="o">=</span><span class="n">fsaverage</span><span class="o">.</span><span class="n">sulc_left</span><span class="p">)</span>

<a href="http://nilearn.github.io/modules/generated/nilearn.plotting.show.html#nilearn.plotting.show" title="View documentation for nilearn.plotting.show"><span class="n">plotting</span><span class="o">.</span><span class="n">show</span></a><span class="p">()</span>
</pre></div>
</div>
<ul class="sphx-glr-horizontal">
<li><a class="first reference internal image-reference" href="../../_images/sphx_glr_plot_localizer_surface_analysis_004.png"><img alt="../../_images/sphx_glr_plot_localizer_surface_analysis_004.png" src="../../_images/sphx_glr_plot_localizer_surface_analysis_004.png" style="width: 376.0px; height: 282.0px;" /></a>
</li>
<li><a class="first reference internal image-reference" href="../../_images/sphx_glr_plot_localizer_surface_analysis_005.png"><img alt="../../_images/sphx_glr_plot_localizer_surface_analysis_005.png" src="../../_images/sphx_glr_plot_localizer_surface_analysis_005.png" style="width: 376.0px; height: 282.0px;" /></a>
</li>
<li><a class="first reference internal image-reference" href="../../_images/sphx_glr_plot_localizer_surface_analysis_006.png"><img alt="../../_images/sphx_glr_plot_localizer_surface_analysis_006.png" src="../../_images/sphx_glr_plot_localizer_surface_analysis_006.png" style="width: 376.0px; height: 282.0px;" /></a>
</li>
</ul>
<p class="sphx-glr-script-out">Out:</p>
<div class="sphx-glr-script-out highlight-default notranslate"><div class="highlight"><pre><span></span><span class="n">Contrast</span>  <span class="mi">1</span> <span class="n">out</span> <span class="n">of</span> <span class="mi">3</span><span class="p">:</span> <span class="n">left</span> <span class="o">-</span> <span class="n">right</span> <span class="n">button</span> <span class="n">press</span><span class="p">,</span> <span class="n">left</span> <span class="n">hemisphere</span>
  <span class="n">Contrast</span>  <span class="mi">2</span> <span class="n">out</span> <span class="n">of</span> <span class="mi">3</span><span class="p">:</span> <span class="n">audio</span> <span class="o">-</span> <span class="n">video</span><span class="p">,</span> <span class="n">left</span> <span class="n">hemisphere</span>
  <span class="n">Contrast</span>  <span class="mi">3</span> <span class="n">out</span> <span class="n">of</span> <span class="mi">3</span><span class="p">:</span> <span class="n">computation</span> <span class="o">-</span> <span class="n">sentences</span><span class="p">,</span> <span class="n">left</span> <span class="n">hemisphere</span>
</pre></div>
</div>
<p><strong>Total running time of the script:</strong> ( 0 minutes  7.862 seconds)</p>
<div class="sphx-glr-footer docutils container">
<div class="sphx-glr-download docutils container">
<a class="reference download internal" href="../../_downloads/plot_localizer_surface_analysis.py" download=""><code class="xref download docutils literal notranslate"><span class="pre">Download</span> <span class="pre">Python</span> <span class="pre">source</span> <span class="pre">code:</span> <span class="pre">plot_localizer_surface_analysis.py</span></code></a></div>
<div class="sphx-glr-download docutils container">
<a class="reference download internal" href="../../_downloads/plot_localizer_surface_analysis.ipynb" download=""><code class="xref download docutils literal notranslate"><span class="pre">Download</span> <span class="pre">Jupyter</span> <span class="pre">notebook:</span> <span class="pre">plot_localizer_surface_analysis.ipynb</span></code></a></div>
</div>
<p class="sphx-glr-signature"><a class="reference external" href="https://sphinx-gallery.readthedocs.io">Generated by Sphinx-Gallery</a></p>
</div>
</div>


          </div>
        </div>
      </div>
      <div class="clearer"></div>
    </div>
    <div class="related" role="navigation" aria-label="related navigation">
      <h3>Navigation</h3>
      <ul>
        <li class="right" style="margin-right: 10px">
          <a href="../../py-modindex.html" title="Python Module Index"
             >modules</a></li>
        <li class="right" >
          <a href="../03_second_level_models/plot_second_level_association_test.html" title="2.3.1. Example of generic design in second-level models"
             >next</a> |</li>
        <li class="right" >
          <a href="plot_bids_features.html" title="2.2.4. First level analysis of a complete BIDS dataset from openneuro"
             >previous</a> |</li>
<li><a href="../../index.html">Nistats Home</a> |&nbsp;</li>
<li><a href="../../user_guide.html">User Guide</a> |&nbsp;</li>
<li><a href="../index.html">Examples</a> |&nbsp;</li>
<li><a href="../../modules/reference.html">Reference</a> |&nbsp;</li>
<li id="navbar-about"><a href="../../authors.html">About</a>|&nbsp;</li>
<li id="navbar-ecosystem"><a href="http://www.nipy.org/">Nipy ecosystem</a></li>

          <li class="nav-item nav-item-1"><a href="../../user_guide.html" >User guide: table of contents</a> &#187;</li>
          <li class="nav-item nav-item-2"><a href="../index.html" >2. Nistats usage examples</a> &#187;</li> 
      </ul>
    </div>
    <div class="footer">
            &copy; The nistats developers 2010-2016.
          Created using <a href="http://sphinx.pocoo.org/">Sphinx</a> 1.7.6.
        <span style="padding-left: 5ex;">
          <a href="../../_sources/auto_examples/02_first_level_models/plot_localizer_surface_analysis.rst.txt"
        	 rel="nofollow">Show this page source</a>
        </span>
    </div>
  </body>
</html>